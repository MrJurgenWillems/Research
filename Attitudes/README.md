Measuring citizen attitudes towards the public sector, public servants, and politicians
=======================================================================================


[JurgenWillems](https://www.researchgate.net/profile/Jurgen_Willems "ResearchGate: Jurgen Willems")

GitHub:
[@MrJurgenWillems](https://github.com/MrJurgenWillems "GitHub: Jurgen Willems")

Twitter:
[@MrJurgenWillems](https://twitter.com/MrJurgenWillems "Twitter: Jurgen Willems")

**Abstract**

This study reports the development and the validation of three related
attitude scales that measure the attitudes of citizens towards the
public sector, the public servants, and the politicians respectively.
With three samples (n1 = 325, n2 = 320, n3 = 337), scale items were
assessed based on item-scale correlations, internal consistency, and
social desirability. Moreover, convergent and discriminant validity were
verified, based on the relatedness of the three attitude scales with
several focal constructs from the public management literature,
including public service motivation and citizens’ trust in government.
In addition, this study outlines the avenues for further research on how
the use of these scales can advance the field of public management, and
particularly behavioral public administration.

**Key words:** Attitudes, public sector, public servants, politicians,
scale development, public service motivation, trust in government.

**Acknowledgements:** I am grateful to Steven Van de Walle, Sebastian
Jilke, Kristina Weißmüller, Matthias Döring, and Dominik Vogel for
suggesting the related scales, which were highly relevant for testing
convergent and discriminant validity of the attitude scales. I would
also like to express my gratitude to Lewis Faulk, Sebastian Jilke,
Steven Van de Walle, Dominik Vogel, and Kristina Weißmüller for their
feedback on the earlier versions of this article.

**Data**: The data and the full analysis protocol (in R) are available
for other researchers to retest, elaborate, and compare these scales and
data sets with new data collections: Willems, J. (2020, June 18). Public
Servants: Stereotypes, attitudes, reputation, and stigmata. Retrieved
from
<a href="https://osf.io/xky93/" class="uri">https://osf.io/xky93/</a>
Keep me posted when you use data, code, input; and/or when you find
‘Glitch’;

Introduction
============

In recent years, the topic of citizen attitudes towards the public
sector and public servants have gained importance in academic literature
(James, Jilke, and Van Ryzin 2017; Grimmelikhuijsen et al. 2017). For
example, Marvel (2016) finds a consistent negative perception among
citizens about public service performance as compared to business
performance. In parallel, negative wide-spread stereotypes about public
servants have also been identified as an area that needs further
attention (Van de Walle 2004). Similarly, citizen attitudes towards
politics and politicians have been identified as a crucial factor in the
behaviors of citizens to participate in public processes (Nielsen 1981;
Inthorn and Street 2011; Henn, Weinstein, and Forrest 2005). With an
increased research focus on citizens’ attitudes towards the public
sector, public servants, and politicians, we can better understand the
individual behaviors of citizens in their interaction with public
institutions and their interactions with public officials within those
institutions (Grimmelikhuijsen et al. 2017). As a consequence, the
public management field can substantially benefit from tools that enable
us to further explore the differences in the engagement of citizens with
public institutions.

However, the present public administration field misses some
broadly-applicable attitude measures that can be used for a wide variety
of research questions and contexts. It is due to this deficiency that
the current approach to quantify the attitudes of citizens often
consists of context-specific measures which have been developed for a
specific analysis (for example, in specific experiment designs), or for
the use of proxy-measures which only partially relate to the actual
attitudes of the citizens (e.g. when secondary data is used from public
service evaluation surveys). Despite the fact that such earlier studies
have great value for theorizing on the attitudes of citizens, the lack
of uniform measures hampers the generalization of findings and the
replication in other settings.

Moreover, the attitudes of citizens can focus on very distinct entities.
Research on attitudes has its origin in social psychology (Thurstone
1928), and it focuses on explaining the individual differences in human
behaviors in relation to a variety of entities (Eagly and Chaiken 2007).
Such entities can be very concrete, such as pertaining to a particular
person (e.g. a politician), or very abstract (e.g. an ideology). The
field of public administration has dealt with the behavior of citizens
in the context of a broad range of relevant entities. However, few
studies have focused on how behavior of citizens is different based on
their attitudes towards distinct public entities. For instance, the
overall and abstract government entity contains more specific entities,
such as politicians, on the one hand, who make policies on how public
institutions should function, and public institutions, on the other
hand. Within these institutions, public servants are an even more
specific entity that has been widely studied in the field of public
administration. As attitudes can be very different for each of these
entities, human behavior is potentially also driven differently by them.
Hence, the research field could thereby additionally benefit from
measurements, each of which focus on specific entities within the broad
area of government services.

This study reports on the development and the validation of three
distinct, yet related, attitude scales. Such survey scales can help
verify theoretical claims and identify avenues for further research.
Hence, attitude scales in the field of public services can especially
advance research that focuses on explaining the differences within
heterogeneous populations. For example, in the research area related to
public service biases, attitude studies can add a substantial nuance by
clarifying the extent to which certain individuals are more susceptible
to such biases as compared to others. In addition, other streams in the
field of public management can benefit from such tools, as attitudes
potentially relate to the expectations and the cognitive processes in
public performance evaluations (Ryzin 2004; Jilke 2017), the choice of
being involved in citizen participation initiatives and co-production
(Whitaker 1980; Irvin and Stansbury 2004 ; Clark and Jang 2013; Roberts
2004), as well as the decision to enter into public service careers (De
Cooman et al. 2011; Becker and Connor 2005; Goulet and Frank 2002;
Willems 2014).

Given the aim of developing and validating measurement scales that are
helpful for other studies, a set of methodological choices has been made
based on four specific goals. First, the study focuses on developing
scales that are sufficiently concise (one-dimensional constructs), so
that they can easily be integrated in surveys and/or experiment
questionnaires, which also contain other constructs. Second, three
uni-dimensional scales have been developed in combination and in
relation to each other. In doing so, this study provides an insight into
the extent to which attitudes towards different entities are similar or
distinct. This enables scholars to choose the right entity focus while
performing further studies and the appropriate scale to measure it.
Third, in order to make the verification quantitative, scales were
measured in two different ways (once with all items randomized, and once
with the items presented as per entity). This provides an insight as to
how the questionnaire format affects the reliability of a scale. This
knowledge can additionally be used by scholars to conduct further
attitude studies. Finally, the scale content was developed to be
relevant across many contexts, and, as a consequence, the focus was not
made on specific public services or government responsibilities, nor on
a specific national or regional context.

Attitudes can be measured towards a broad range of entities, such as an
organization, a product, an ideology, an individual, or a group of
people (Gawronski 2007). Three focal entities were chosen from a broad
range of potentially relevant government-related entities: the public
sector, public servants, and politicians. A separate attitude scale was
developed and validated for each of these foci. Simultaneously
validating these three scales enabled clarifying both the relatedness
and the distinctness of citizen attitudes towards these three entities.
Hence, the choice was made not to develop a scale that focused only on
one entity or a concept with several sub-dimensions (e.g. four
sub-dimensions in the overall construct of public service motivation
(Kim et al. 2013; Perry and Wise 1990) or three dimensions in citizens’
trust in governmental organizations (Grimmelikhuijsen and Knies 2017)),
but on the simultaneous validation of three related, but distinct,
scales. Therefore, the next section provides an insight into the
theoretical background, which is at the basis for simultaneously
deriving scale items for these three entities. The methodology section
reports on the various tests that have been done to assess scale
validity, based on three data samples. In the discussion section,
attention has been paid to how a stronger focus on individual attitudes
in public management can advance various research streams.

Citizen attitudes in the public sector and political context
============================================================

Attitudes can be defined as “a psychological tendency that is expressed
by evaluating a particular entity with some degree of favor or disfavor”
(Eagly and Chaiken 1993, 1; cited in Gawronski 2007, p575). As a result,
attitudes can be measured towards a broad set of entities, including
people, organizations, products, ideas, ideologies, groups in society,
sectors, nationalities, etc. (Eagly and Chaiken 2007) Moreover,
attitudes can be measured among the general population, or among certain
groups, such as youth, the workforce, managers, or customers.

Since Thurstone (1928) introduced attitudes as a measurable construct,
attitudes have “become one of the most important constructs in social
psychology. In fact, it is difficult to imagine what contemporary social
psychology would be like without the concept of attitude” (Gawronski
2007, p573). The concept of attitudes has established itself as a
crucial factor to explain individual behavior not only within social
psychology, but within a wide range of social sciences and disciplines.

With respect to various entities in the field of government research,
attitudes have been measured and analyzed within a broad range of
research fields and sub-domains. One such domain focuses on job
attitudes of the public servants themselves, in which job attitudes are
analyzed as a function of organizational context and management
practices (Gould-Williams 2004; Albrecht and Travaglione 2003). For
example, Vigoda (2000) investigated the effect of organizational
politics in public institutes regarding the attitudes of public servants
towards their own jobs and have found a negative effect on the
organizational politics.

From the perspective of a citizen, the focus of the research has been
made on attitudes towards particular services and their public nature,
such as public versus private transport (Beirão and Cabral 2007),
e-governance and e-government (Kolsaker and Lee‐Kelley 2008), and
wind-power policies (Ek 2005). On a more abstract level, attitudes
towards democracy explain people’s trust in government and in public
sector reforms (Christensen and Lægreid 2003). Moreover, attitudes
towards politics in general can further be subdivided, as they can vary
differently for distinct government levels (Nielsen 1981). This shows
that it is appropriate to make a distinction between the operational
public services aspect of government and the strategic, political
component of it.

In contrast to the more abstract level of attitudes towards
government-related entities, very specific individuals can also be the
focal entities of research. For example, Inthorn and Street (2011)
investigate how celebrity politics, which is the process by which
popular celebrities openly endorse politicians and their political
programs, can influence the attitudes of youth towards politics. Their
research suggests that strongly communicated authenticity about
politicians can improve the attitudes of youths towards politics, which,
in turn, can influence the choice of young citizens to vote (Henn,
Weinstein, and Forrest 2005).

A specific stream of literature has focused on whether the overall
attitudes towards government-related entities are either positive or
negative. As compared to the private for-profit sector, studies have
found that people have a negative attitude towards public service
entities (e.g. Marvel 2016). For example, the public sector is often
typified as being bureaucratic, slow, and inefficient (Pandey, Coursey,
and Moynihan 2007; Marvel 2016; Olsen 2015), which might, in turn,
influence the overall attitudes of citizens about public servants and
about the political systems in which they operate (Bean and Papadakis
1998). For example, public employees are often portrayed as being lazy,
risk-averse, or corrupt in popular media and movies, which strengthen
the wide-spread stereotypical thinking about them (Van de Walle 2004).

Methodology
===========

Developing and validating the related scales happened in five steps,
following general recommendations on scale development and validation
(Bollen and Richard 1991; Foddy 1993; Scherpenzeel and Saris 1997;
Borsboom, Mellenbergh, and Heerden 2003; DeVellis 2003). Items and scale
validations were based on three distinct samples obtained from two large
data collections. Respondents were addressed through Amazon Mechanical
Turk (MTurk) for all data collections.

All analyses were conducted in R (R Core Team 2017), with special use
being made of the packages lavaan (Rosseel 2012), psych (Revelle 2017),
Scale (Giallousis 2015), and corrplot (Wei and Simko 2017). The original
data, along with the complete analysis protocol, can be found in the
online appendix. (This link has been removed for blind review, and is
currently NOT available online). This should encourage other researchers
to build on this study to further evaluate the scales (e.g. with
alternative methods), compare new data collections with the data samples
of this study (e.g. in other languages), and/or perform more advanced
and additional analyses (e.g. group comparisons based on demographic
background variables).

``` r
library("lavaan")
library("psych")
library("Scale")
library("corrplot")
```

Step 1: Item generation for three related constructs
----------------------------------------------------

Adding to the literature that has been postulated above, a list of
characteristics about the public sector, public servants, and
politicians was derived first. Characteristics were further explored
based on the publicly available data on 7,470 word associations by 415
U.S. respondents for 12 professions, including public servants and
politicians (Willems 2020a, 2020b , 2020c)). [**Figure
1**](https://doi.org/10.6084/m9.figshare.12505415) and [**Figure
2**](https://doi.org/10.6084/m9.figshare.12505430) give the word clouds
of most associated words for the categories public servant and
politician. These characteristics were then used to develop a series of
short survey items. In order to increase content validity, the initial
list of items was complemented with lists from individuals who were not
associated with the study. Moreover, I started interviewing additional
individuals until the lists became redundant and no new items were
added. The lists from these interviews included typical associations
that are made about the public sector, the public servants, and the
politicians by individuals who are not familiar with the academic
literature on the subject. This helped verify and extend my initial
ideas which were mainly based on the available literature that was
reviewed for this study, and it also worked in limiting my own potential
personal bias. In all, there were high levels of redundancy across the
interviews. This indicated the high degrees of overlapping between
academic studies on the subject and lay impressions, and gave confidence
that there was a sufficient level of saturation among the items in the
study relative to the potential constructs of interest. To avoid
acquiescence biases in scale responses (Billiet and Davidov 2008),
several items were formulated in the reverse order. In total, 15 items
were derived for each focus category (public sector, public servants,
and politicians). Subsequently, a final list of 45 items was proofread
and evaluated for clarity and exhaustiveness by two native
English-speaking scholars in the field of public and non-profit
management. The full list of items is given in Table 1.

The items were formulated in such a manner that they could be answered
with a 7-point Likert scale, whose elements are as follows: ‘Strongly
disagree’ (-3), ‘Disagree’ (-2), ‘Somewhat disagree’ (-1), ‘Neither
agree nor disagree’ (0), ‘Somewhat agree’ (1), ‘Agree’ (2), ‘Strongly
agree’ (3). The 7-point scale was chosen as it gives the respondents the
opportunity to add more nuance to their answers (as compared to a
5-point scale) (Norman 2010; Alwin 1997).

Moreover, the numeric labels from -3 to +3 has the additional advantage
that the sign of a scale value informs us about the absolute
negativeness or positiveness in terms of attitudes. For example, in a
regression in which an (aggregate) attitude score is explained as a
dependent variable, a non-significant constant means that on an average
and with all independent variables being zero, a neutral answer was
recorded on the scale. In contrast, a significant positive or negative
constant provides an indication whether scales were answered in a
particular direction.

Step 2: Analysis of two samples to evaluate item quality and construct reliability
----------------------------------------------------------------------------------

``` r
# Data for the first datacollection, with samples 1a and 1b can be downloaded here: https://osf.io/xky93/ 
DATA <- read.csv("DATA/ScalePublicServAttitudes(SAMPLES 1 AND 2).csv", header = TRUE, sep = ",")
n_started <- nrow(DATA)
# Deleting respondents that did not finish questionnaire
DATA  <-subset(DATA, V10 == 1)   #'V10' is the variable from the Qualtrics output that indicates wheter a respondent answered untill the last page.
n_finished <- nrow(DATA)

# Derive two subsample, depending on the random stream in wich respondents were directed.
Sample.1a <-subset(DATA, Intro_Shuffled == 1)  # This is the group of respondents that received all items in randon order, regardless the items focus on public sector, public servants, or politicians
Sample.1b <-subset(DATA, Intro_Separate == 1) # This is the group of respondents that received items in batches, grouped per focus on public sector, public servants, or politicians. The three batches of 15 items were however randomized.
n_sample.1a_orig <- nrow(Sample.1a)
n_sample.1b_orig <- nrow(Sample.1b)

# Deleting respondents that did not answer all three attention questions in their stream correctly.
Sample.1a <-subset(Sample.1a, A16 == 3 & A32 == 0 & A48 == -3 ) 
Sample.1b <-subset(Sample.1b, B16 == -3 & B32 == +3 & B48 == 0 )
n_sample.1a <- nrow(Sample.1a)
n_sample.1b <- nrow(Sample.1b)

# to report on background variables - see further
Sample.Demographics <-subset(DATA, select = c("Birthyear" , "English" , "Occupation" , "Education"))
Sample.Demographics.emp <-subset(DATA, Org_intro == 1, select = c("Org_Experience" , "Org_Type" , "Org_Size" ))
```

``` r
# Item-scale corelation and item consistency with other items (internal scale consistency)
## 1. Subsets for the separate scale analyses
Sample.1a.PubSec <-subset(Sample.1a, select = c("A01_PubSec01" , "A04_PubSec02" , "A07_PubSec03" , "A10_PubSec04" , "A13_PubSec05" , "A17_PubSec06"  , "A20_PubSec07"  , "A23_PubSec08"  , "A26_PubSec09"  , "A29_PubSec10"  ,  "A33_PubSec11" ,  "A36_PubSec12" ,  "A39_PubSec13" ,  "A42_PubSec14" ,  "A45_PubSec15"))
Sample.1a.PubServ <-subset(Sample.1a, select = c("A02_PubServ01","A05_PubServ02", "A08_PubServ03" , "A11_PubServ04" , "A14_PubServ05" , "A18_PubServ06" , "A21_PubServ07" ,  "A24_PubServ08",  "A27_PubServ09", "A30_PubServ10" , "A34_PubServ11" , "A37_PubServ12" , "A40_PubServ13" , "A43_PubServ14", "A46_PubServ15"))
Sample.1a.pol <-subset(Sample.1a, select = c("A03_Pol01" , "A06_Pol02" , "A09_Pol03",  "A12_Pol04" , "A15_Pol05", "A19_Pol06" , "A22_Pol07" , "A25_Pol08", "A28_Pol09" , "A31_Pol10" , "A35_Pol11" , "A38_Pol12" , "A41_Pol13" , "A44_Pol14" , "A47_Pol15" ))
Sample.1b.PubSec <-subset(Sample.1b, select = c("B01_PubSec01", "B02_PubSec02", "B03_PubSec03", "B04_PubSec04", "B05_PubSec05", "B06_PubSec06", "B07_PubSec07", "B08_PubSec08", "B09_PubSec09", "B10_PubSec10", "B11_PubSec11", "B12_PubSec12", "B13_PubSec13", "B14_PubSec14", "B15_PubSec15"))
Sample.1b.PubServ <-subset(Sample.1b, select = c("B17_PubServ01", "B18_PubServ02", "B19_PubServ03", "B20_PubServ04", "B21_PubServ05", "B22_PubServ06", "B23_PubServ07", "B24_PubServ08", "B25_PubServ09", "B26_PubServ10", "B27_PubServ11", "B28_PubServ12", "B29_PubServ13", "B30_PubServ14", "B31_PubServ15"))
Sample.1b.pol <-subset(Sample.1b, select = c("B33_Pol01", "B34_Pol02", "B35_Pol03", "B36_Pol04", "B37_Pol05", "B38_Pol06", "B39_Pol07", "B40_Pol08", "B41_Pol09", "B42_Pol10", "B43_Pol11", "B44_Pol12", "B45_Pol13", "B46_Pol14", "B47_Pol15"))
### 1.1. Attitudes towards Public Sector

#### 1.1.1. Sample 1a: randomly mixed items
Scale.Sample.1a.PubSec <- Scale(data = Sample.1a.PubSec, reverse = c("A10_PubSec04", "A17_PubSec06", "A20_PubSec07", "A26_PubSec09", "A29_PubSec10", "A33_PubSec11", "A36_PubSec12"))
prep.Sample.1a.PubSec <- PreProc(Scale.Sample.1a.PubSec)
it.Sample.1a.PubSec <- ItemAnalysis(prep.Sample.1a.PubSec, method="spearman", fm="gls", nfactors=1, rcut= 0.4, score_type="z", exclude=c(10, 13, 15)) # These items are excluded, based on this and folowing analyses. Leaving the vector empty will return the initial analysis: exclude=c()
it.Sample.1a.PubSec
```

    ## 
    ## Reliability Analysis of prep.Sample.1a.PubSec ScaleData object. 
    ## 
    ## A spearman correlation matrix of 12 items was calculated and submitted to Reliability analysis.
    ##       
    ## The overall Cronbach's Alpha was 0.88 .
    ## A gls factor analysis was conducted. Items were regressed to
    ##       a single factor. Their loadings are the following:
    ## A10_PubSec04 A33_PubSec11 A26_PubSec09 A20_PubSec07 A01_PubSec01 
    ##    0.5314701    0.5624258    0.5689352    0.5816496    0.6421491 
    ## A04_PubSec02 A42_PubSec14 A23_PubSec08 A17_PubSec06 A07_PubSec03 
    ##    0.6429739    0.6461189    0.6659871    0.6665641    0.6705856 
    ## A36_PubSec12 A13_PubSec05 
    ##    0.6748044    0.6786383

``` r
it.Sample.1a.PubSec$rely$alpha$total
```

    ##  raw_alpha std.alpha   G6(smc) average_r      S/N  median_r
    ##  0.8832026 0.8832026 0.9091167 0.3865607 7.561836 0.3812092

``` r
ChooseBest(it.Sample.1a.PubSec, n=4)
```

    ## [1] "A13_PubSec05" "A36_PubSec12" "A07_PubSec03" "A17_PubSec06"

``` r
#Initial alpha: 0.9 ; Delete item(s): A45_PubSec15 

#### 1.1.2.  Sample 1b: items per entity
Scale.Sample.1b.PubSec <- Scale(data = Sample.1b.PubSec, reverse = c("B04_PubSec04", "B06_PubSec06", "B07_PubSec07", "B09_PubSec09", "B10_PubSec10", "B11_PubSec11", "B12_PubSec12"))
prep.Sample.1b.PubSec <- PreProc(Scale.Sample.1b.PubSec)
it.Sample.1b.PubSec <- ItemAnalysis(prep.Sample.1b.PubSec, method="spearman", fm="gls", nfactors=1, rcut= 0.4, score_type="z", exclude=c(10, 13, 15)) # These items are excluded, based on this and folowing analyses. Leaving the vector empty will return the initial analysis: exclude=c()
it.Sample.1b.PubSec
```

    ## 
    ## Reliability Analysis of prep.Sample.1b.PubSec ScaleData object. 
    ## 
    ## A spearman correlation matrix of 12 items was calculated and submitted to Reliability analysis.
    ##       
    ## The overall Cronbach's Alpha was 0.91 .
    ## A gls factor analysis was conducted. Items were regressed to
    ##       a single factor. Their loadings are the following:
    ## B11_PubSec11 B04_PubSec04 B01_PubSec01 B07_PubSec07 B09_PubSec09 
    ##    0.5612580    0.6038718    0.6398893    0.6429158    0.6531026 
    ## B14_PubSec14 B02_PubSec02 B05_PubSec05 B06_PubSec06 B03_PubSec03 
    ##    0.6566809    0.6570839    0.7169822    0.7286594    0.7641649 
    ## B12_PubSec12 B08_PubSec08 
    ##    0.7662347    0.7736368

``` r
ChooseBest(it.Sample.1b.PubSec, n=4)
```

    ## [1] "B08_PubSec08" "B12_PubSec12" "B03_PubSec03" "B06_PubSec06"

``` r
#Initial alpha: 0.92; Delete item(s): none

### 1.2. Attitudes towards Public Servants

#####  1.2.1. Sample 1a: randomly mixed items
Scale.Sample.1a.PubServ <- Scale(data = Sample.1a.PubServ, reverse = c("A14_PubServ05", "A18_PubServ06", "A30_PubServ10", "A40_PubServ13", "A43_PubServ14", "A46_PubServ15"))
prep.Sample.1a.PubServ <- PreProc(Scale.Sample.1a.PubServ)
it.Sample.1a.PubServ <- ItemAnalysis(prep.Sample.1a.PubServ, method="spearman", fm="gls", nfactors=1, rcut= 0.4, score_type="z", exclude=c(2, 3, 5, 13)) # These items are excluded, based on this and folowing analyses. Leaving the vector empty will return the initial analysis: exclude=c()
it.Sample.1a.PubServ
```

    ## 
    ## Reliability Analysis of prep.Sample.1a.PubServ ScaleData object. 
    ## 
    ## A spearman correlation matrix of 11 items was calculated and submitted to Reliability analysis.
    ##       
    ## The overall Cronbach's Alpha was 0.9 .
    ## A gls factor analysis was conducted. Items were regressed to
    ##       a single factor. Their loadings are the following:
    ## A11_PubServ04 A46_PubServ15 A18_PubServ06 A43_PubServ14 A37_PubServ12 
    ##     0.5163093     0.5589332     0.5618259     0.5880044     0.7110005 
    ## A27_PubServ09 A24_PubServ08 A34_PubServ11 A30_PubServ10 A02_PubServ01 
    ##     0.7275124     0.7378683     0.7425062     0.7549713     0.7684246 
    ## A21_PubServ07 
    ##     0.7826206

``` r
ChooseBest(it.Sample.1a.PubServ, n=4)
```

    ## [1] "A21_PubServ07" "A02_PubServ01" "A30_PubServ10" "A34_PubServ11"

``` r
#Initial alpha: 0.90 ; Delete item(s): 'A14_PubServ05' and 'A40_PubServ13' 

##### 1.2.2. Sample 1b: items per entity
Scale.Sample.1b.PubServ <- Scale(data = Sample.1b.PubServ, reverse = c("B21_PubServ05", "B22_PubServ06", "B26_PubServ10", "B29_PubServ13", "B30_PubServ14", "B31_PubServ15"))
prep.Sample.1b.PubServ <- PreProc(Scale.Sample.1b.PubServ)
it.Sample.1b.PubServ <- ItemAnalysis(prep.Sample.1b.PubServ, method="spearman", fm="gls", nfactors=1, rcut= 0.4, score_type="z", exclude=c(2, 3, 5, 13)) # These items are excluded, based on this and folowing analyses. Leaving the vector empty will return the initial analysis: exclude=c()
it.Sample.1b.PubServ
```

    ## 
    ## Reliability Analysis of prep.Sample.1b.PubServ ScaleData object. 
    ## 
    ## A spearman correlation matrix of 11 items was calculated and submitted to Reliability analysis.
    ##       
    ## The overall Cronbach's Alpha was 0.92 .
    ## Furthermore, deleting item(s) 10 may improve reliability.A gls factor analysis was conducted. Items were regressed to
    ##       a single factor. Their loadings are the following:
    ## B30_PubServ14 B20_PubServ04 B22_PubServ06 B31_PubServ15 B25_PubServ09 
    ##     0.5618558     0.5802257     0.6576625     0.6971549     0.7207703 
    ## B24_PubServ08 B26_PubServ10 B28_PubServ12 B27_PubServ11 B23_PubServ07 
    ##     0.7382265     0.7609524     0.7769463     0.7943724     0.8453326 
    ## B17_PubServ01 
    ##     0.8496447

``` r
ChooseBest(it.Sample.1b.PubServ, n=4)
```

    ## [1] "B17_PubServ01" "B23_PubServ07" "B27_PubServ11" "B28_PubServ12"

``` r
#Initial alpha: 0.93; Delete item(s): B19_PubServ03

### 1.3. Attitudes towards Politicians
##### 1.3.1. Sample 1a: randomly mixed items

Scale.Sample.1a.pol <- Scale(data = Sample.1a.pol, reverse = c("A15_Pol05", "A19_Pol06", "A31_Pol10", "A44_Pol14"))
prep.Sample.1a.pol <- PreProc(Scale.Sample.1a.pol)
it.Sample.1a.pol <- ItemAnalysis(prep.Sample.1a.pol, method="spearman" , fm="gls", nfactors=1, rcut= 0.4, score_type="z", exclude=c(2, 4, 5, 7, 8, 9, 12,14,15)) # These items are excluded, based on this and folowing analyses. Leaving the vector empty will return the initial analysis: exclude=c()
it.Sample.1a.pol
```

    ## 
    ## Reliability Analysis of prep.Sample.1a.pol ScaleData object. 
    ## 
    ## A spearman correlation matrix of 6 items was calculated and submitted to Reliability analysis.
    ##       
    ## The overall Cronbach's Alpha was 0.87 .
    ## Furthermore, deleting item(s) 3 may improve reliability.A gls factor analysis was conducted. Items were regressed to
    ##       a single factor. Their loadings are the following:
    ## A19_Pol06 A31_Pol10 A41_Pol13 A35_Pol11 A09_Pol03 A03_Pol01 
    ## 0.4521766 0.5901311 0.7893801 0.8382499 0.8412723 0.8664245

``` r
# Initial alpha: 0.89; Delete item(s): 4,5,12 and 14 (Low correlation), 4,5,12 and 14 (reduced reliability)

#####  1.3.2. Sample 1b: items per entity
Scale.Sample.1b.pol <- Scale(data = Sample.1b.pol, reverse = c("B37_Pol05", "B38_Pol06", "B42_Pol10", "B46_Pol14"))
prep.Sample.1b.pol <- PreProc(Scale.Sample.1b.pol)
it.Sample.1b.pol <- ItemAnalysis(prep.Sample.1b.pol, method="spearman" , fm="gls", nfactors=1, rcut= 0.4, score_type="z", exclude=c(2, 4, 5, 7, 8, 9, 12,14,15)) # These items are excluded, based on this and folowing analyses. Leaving the vetcor empty will return the inital analysis: exclude=c()
it.Sample.1b.pol
```

    ## 
    ## Reliability Analysis of prep.Sample.1b.pol ScaleData object. 
    ## 
    ## A spearman correlation matrix of 6 items was calculated and submitted to Reliability analysis.
    ##       
    ## The overall Cronbach's Alpha was 0.89 .
    ## Furthermore, deleting item(s) 3 may improve reliability.A gls factor analysis was conducted. Items were regressed to
    ##       a single factor. Their loadings are the following:
    ## B38_Pol06 B42_Pol10 B45_Pol13 B43_Pol11 B35_Pol03 B33_Pol01 
    ## 0.4574358 0.6661005 0.7965028 0.8286150 0.8713211 0.9047862

``` r
# Initial alpha: 0.90 ; Delete item(s): Pol04,Pol05 and Pol14 (Low correlation), DELETE:  4,5 and 14 (reduced reliability)
```

``` r
# Social Desirabilty (SD)
## 1. Select sub-samples for SD scale analysis
### 1.1. Sample 1a
Sample.1a.socdes <-subset(Sample.1a, select = c("Social_desirability_1" , "Social_desirability_2" ,"Social_desirability_3" ,"Social_desirability_4" , "Social_desirability_5" ,"Social_desirability_6" ,"Social_desirability_7" ,"Social_desirability_8" ,"Social_desirability_9" ,"Social_desirability_10"))
Scale.Sample.1a.socdes <- Scale(data = Sample.1a.socdes, reverse = c("Social_desirability_6" , "Social_desirability_7" ,"Social_desirability_8" ,"Social_desirability_9" ,"Social_desirability_10"))
prep.Sample.1a.socdes <- PreProc(Scale.Sample.1a.socdes)
it.Sample.1a.socdes <- ItemAnalysis(prep.Sample.1a.socdes, method="spearman", fm="gls", nfactors=1, rcut= 0.4, score_type="z", exclude=c())
it.Sample.1a.socdes
```

    ## 
    ## Reliability Analysis of prep.Sample.1a.socdes ScaleData object. 
    ## 
    ## A spearman correlation matrix of 10 items was calculated and submitted to Reliability analysis.
    ##       
    ## The overall Cronbach's Alpha was 0.81 .
    ## A gls factor analysis was conducted. Items were regressed to
    ##       a single factor. Their loadings are the following:
    ##  Social_desirability_9  Social_desirability_4  Social_desirability_2 
    ##              0.4781452              0.4948078              0.4948375 
    ## Social_desirability_10  Social_desirability_5  Social_desirability_6 
    ##              0.5406363              0.5433196              0.5572214 
    ##  Social_desirability_1  Social_desirability_8  Social_desirability_3 
    ##              0.5650724              0.5970027              0.6232073 
    ##  Social_desirability_7 
    ##              0.6836738

``` r
it.Sample.1a.socdes$rely$alpha
```

    ## 
    ## Reliability analysis   
    ## Call: psych::alpha(x = cor_matrix)
    ## 
    ##   raw_alpha std.alpha G6(smc) average_r S/N median_r
    ##       0.81      0.81    0.82      0.29 4.2      0.3
    ## 
    ##  Reliability if an item is dropped:
    ##                        raw_alpha std.alpha G6(smc) average_r S/N var.r
    ## Social_desirability_1       0.79      0.79    0.80      0.29 3.7 0.011
    ## Social_desirability_2       0.80      0.80    0.80      0.30 3.9 0.010
    ## Social_desirability_3       0.78      0.78    0.80      0.28 3.6 0.015
    ## Social_desirability_4       0.80      0.80    0.81      0.30 3.9 0.014
    ## Social_desirability_5       0.79      0.79    0.81      0.30 3.8 0.016
    ## Social_desirability_6       0.79      0.79    0.81      0.30 3.8 0.016
    ## Social_desirability_7       0.77      0.77    0.79      0.28 3.4 0.015
    ## Social_desirability_8       0.79      0.79    0.80      0.29 3.7 0.016
    ## Social_desirability_9       0.80      0.80    0.81      0.31 4.0 0.013
    ## Social_desirability_10      0.79      0.79    0.81      0.30 3.8 0.015
    ##                        med.r
    ## Social_desirability_1   0.30
    ## Social_desirability_2   0.31
    ## Social_desirability_3   0.30
    ## Social_desirability_4   0.31
    ## Social_desirability_5   0.30
    ## Social_desirability_6   0.30
    ## Social_desirability_7   0.29
    ## Social_desirability_8   0.30
    ## Social_desirability_9   0.31
    ## Social_desirability_10  0.30
    ## 
    ##  Item statistics 
    ##                           r r.cor r.drop
    ## Social_desirability_1  0.61  0.58   0.49
    ## Social_desirability_2  0.55  0.50   0.42
    ## Social_desirability_3  0.67  0.63   0.56
    ## Social_desirability_4  0.56  0.49   0.43
    ## Social_desirability_5  0.59  0.52   0.47
    ## Social_desirability_6  0.60  0.53   0.47
    ## Social_desirability_7  0.71  0.68   0.61
    ## Social_desirability_8  0.63  0.57   0.51
    ## Social_desirability_9  0.53  0.46   0.40
    ## Social_desirability_10 0.59  0.53   0.47

``` r
Scores.socdes.a <- it.Sample.1a.socdes$valid$scores

### 1.2. Sample 1b
Sample.1b.socdes <-subset(Sample.1b, select = c("Social_desirability_1" , "Social_desirability_2" ,"Social_desirability_3" ,"Social_desirability_4" ,"Social_desirability_5" ,"Social_desirability_6" ,"Social_desirability_7" ,"Social_desirability_8" ,"Social_desirability_9" ,"Social_desirability_10"))
Scale.Sample.1b.socdes <- Scale(data = Sample.1b.socdes, reverse = c("Social_desirability_6" , "Social_desirability_7" ,"Social_desirability_8" ,"Social_desirability_9" ,"Social_desirability_10"))
prep.Sample.1b.socdes <- PreProc(Scale.Sample.1b.socdes)
it.Sample.1b.socdes <- ItemAnalysis(prep.Sample.1b.socdes, method="spearman", fm="gls", nfactors=1, rcut= 0.4, score_type="z", exclude=c()) 
it.Sample.1b.socdes
```

    ## 
    ## Reliability Analysis of prep.Sample.1b.socdes ScaleData object. 
    ## 
    ## A spearman correlation matrix of 10 items was calculated and submitted to Reliability analysis.
    ##       
    ## The overall Cronbach's Alpha was 0.83 .
    ## A gls factor analysis was conducted. Items were regressed to
    ##       a single factor. Their loadings are the following:
    ## Social_desirability_10  Social_desirability_2  Social_desirability_1 
    ##              0.4608926              0.4757205              0.5393079 
    ##  Social_desirability_6  Social_desirability_8  Social_desirability_5 
    ##              0.5529017              0.5907855              0.5997608 
    ##  Social_desirability_4  Social_desirability_9  Social_desirability_3 
    ##              0.6047076              0.6220338              0.6433509 
    ##  Social_desirability_7 
    ##              0.7254187

``` r
Scores.socdes.b <- it.Sample.1b.socdes$valid$scores

## 2. Attitudes towards Public Sector
### 2.1. Sample 1a: randomly mixed items
COR <- cbind(Sample.1a.PubSec, Scores.socdes.a)
COR <- rcorr(as.matrix(COR), type="spearman") # type can be pearson or spearman
cbind(COR$r[16,],COR$P[16,])
```

    ##                        [,1]       [,2]
    ## A01_PubSec01    -0.05982521 0.28223046
    ## A04_PubSec02    -0.03618484 0.51567226
    ## A07_PubSec03    -0.03705992 0.50556345
    ## A10_PubSec04    -0.01109053 0.84212729
    ## A13_PubSec05    -0.09848908 0.07622723
    ## A17_PubSec06    -0.04768679 0.39152167
    ## A20_PubSec07     0.01867327 0.73734650
    ## A23_PubSec08    -0.10086141 0.06938074
    ## A26_PubSec09     0.02895769 0.60296606
    ## A29_PubSec10     0.02615752 0.63848010
    ## A33_PubSec11    -0.01980757 0.72203141
    ## A36_PubSec12     0.01797955 0.74676475
    ## A39_PubSec13     0.03793344 0.49557719
    ## A42_PubSec14    -0.05991154 0.28153533
    ## A45_PubSec15    -0.02384080 0.66850479
    ## Scores.socdes.a  1.00000000         NA

``` r
subset(cbind(COR$r[16,],COR$P[16,]), COR$P[16,] < 0.0500000)# the set of items that should be deleted
```

    ##      [,1] [,2]

``` r
#DELETE: none

### 2.2. Sample 1b: items per entity
#cor(Sample.1b.PubSec, y = Scores.socdes.b, use = "everything", method = "spearman")
COR <- cbind(Sample.1b.PubSec, Scores.socdes.b)
COR <- rcorr(as.matrix(COR), type="spearman") # type can be pearson or spearman
cbind(COR$r[16,],COR$P[16,])
```

    ##                         [,1]       [,2]
    ## B01_PubSec01    -0.082736638 0.13973485
    ## B02_PubSec02     0.006286247 0.91081322
    ## B03_PubSec03    -0.006881178 0.90241277
    ## B04_PubSec04     0.032133271 0.56683705
    ## B05_PubSec05     0.009335333 0.86788495
    ## B06_PubSec06    -0.003300604 0.95310176
    ## B07_PubSec07     0.029535741 0.59861124
    ## B08_PubSec08     0.029881582 0.59433464
    ## B09_PubSec09    -0.004764286 0.93234637
    ## B10_PubSec10     0.110801301 0.04765643
    ## B11_PubSec11     0.027287296 0.62674713
    ## B12_PubSec12    -0.051330581 0.36006589
    ## B13_PubSec13    -0.132874107 0.01739847
    ## B14_PubSec14    -0.034499759 0.53860858
    ## B15_PubSec15    -0.104970817 0.06070863
    ## Scores.socdes.b  1.000000000         NA

``` r
subset(cbind(COR$r[16,],COR$P[16,]), COR$P[16,] < 0.0500000)# the set of items that should be deleted
```

    ##                    [,1]       [,2]
    ## B10_PubSec10  0.1108013 0.04765643
    ## B13_PubSec13 -0.1328741 0.01739847

``` r
#DELETE: PubSec10, PubSec13

## 3. Attitudes towards Public Servants
### 3.1. Sample 1a: randomly mixed items
#cor(Sample.1a.PubServ, y = Scores.socdes.a, use = "everything", method = "spearman")
COR <- cbind(Sample.1a.PubServ, Scores.socdes.a)
COR <- rcorr(as.matrix(COR), type="spearman") # type can be pearson or spearman
cbind(COR$r[16,],COR$P[16,])
```

    ##                         [,1]       [,2]
    ## A02_PubServ01    0.008559648 0.87783090
    ## A05_PubServ02   -0.105602593 0.05720209
    ## A08_PubServ03   -0.112869642 0.04200722
    ## A11_PubServ04   -0.028447464 0.60937109
    ## A14_PubServ05    0.049156412 0.37707448
    ## A18_PubServ06    0.039434332 0.47866646
    ## A21_PubServ07   -0.020887541 0.70755221
    ## A24_PubServ08    0.020456221 0.71332268
    ## A27_PubServ09   -0.109939480 0.04766619
    ## A30_PubServ10    0.062126216 0.26409694
    ## A34_PubServ11    0.054686973 0.32569580
    ## A37_PubServ12   -0.011083428 0.84222708
    ## A40_PubServ13   -0.098564077 0.07600268
    ## A43_PubServ14   -0.019081516 0.73182212
    ## A46_PubServ15    0.085528446 0.12386144
    ## Scores.socdes.a  1.000000000         NA

``` r
subset(cbind(COR$r[16,],COR$P[16,]), COR$P[16,] < 0.0500000)# the set of items that should be deleted
```

    ##                     [,1]       [,2]
    ## A08_PubServ03 -0.1128696 0.04200722
    ## A27_PubServ09 -0.1099395 0.04766619

``` r
#Delete: PubServ03

### 3.2. Sample 1b: items per entity
#cor(Sample.1b.PubServ, y = Scores.socdes.b, use = "everything", method = "spearman")
COR <- cbind(Sample.1b.PubServ, Scores.socdes.b)
COR <- rcorr(as.matrix(COR), type="spearman") # type can be pearson or spearman
cbind(COR$r[16,],COR$P[16,])
```

    ##                          [,1]       [,2]
    ## B17_PubServ01   -0.0646067046 0.24915612
    ## B18_PubServ02   -0.1033876065 0.06472263
    ## B19_PubServ03    0.0060663271 0.91392106
    ## B20_PubServ04   -0.0017832739 0.97465119
    ## B21_PubServ05   -0.0187686614 0.73803275
    ## B22_PubServ06    0.0005525321 0.99214470
    ## B23_PubServ07   -0.0936753574 0.09435911
    ## B24_PubServ08   -0.0412395507 0.46225337
    ## B25_PubServ09   -0.0448866917 0.42358406
    ## B26_PubServ10   -0.0135088411 0.80977305
    ## B27_PubServ11   -0.0605456105 0.28021996
    ## B28_PubServ12   -0.0868365239 0.12108638
    ## B29_PubServ13   -0.0339930969 0.54459277
    ## B30_PubServ14    0.0155692441 0.78144378
    ## B31_PubServ15    0.0255031941 0.64946637
    ## Scores.socdes.b  1.0000000000         NA

``` r
subset(cbind(COR$r[16,],COR$P[16,]), COR$P[16,] < 0.0500000)# the set of items that should be deleted
```

    ##      [,1] [,2]

``` r
#DELETE: PubServ02 

## 4. Attitudes towards Politicians
### 4.1. Sample 1a: randomly mixed items
#cor(Sample.1a.pol, y = Scores.socdes.a, use = "everything", method = "spearman")
COR <- cbind(Sample.1a.pol, Scores.socdes.a)
COR <- rcorr(as.matrix(COR), type="spearman") # type can be pearson or spearman
cbind(COR$r[16,],COR$P[16,])
```

    ##                         [,1]      [,2]
    ## A03_Pol01       -0.033956947 0.5418719
    ## A06_Pol02        0.082003675 0.1401771
    ## A09_Pol03       -0.033989932 0.5414792
    ## A12_Pol04       -0.091923574 0.0980676
    ## A15_Pol05        0.089053014 0.1090615
    ## A19_Pol06       -0.004149992 0.9405910
    ## A22_Pol07        0.078472202 0.1581254
    ## A25_Pol08        0.043388353 0.4356569
    ## A28_Pol09        0.055315179 0.3201607
    ## A31_Pol10        0.002657227 0.9619399
    ## A35_Pol11       -0.004077999 0.9416197
    ## A38_Pol12        0.031072796 0.5767425
    ## A41_Pol13       -0.001152979 0.9834805
    ## A44_Pol14        0.024965799 0.6538551
    ## A47_Pol15        0.076374058 0.1695799
    ## Scores.socdes.a  1.000000000        NA

``` r
subset(cbind(COR$r[16,],COR$P[16,]), COR$P[16,] < 0.0500000)# the set of items that should be deleted
```

    ##      [,1] [,2]

``` r
# DELETE: A06_Pol02 ; A15_Pol05 ;A22_Pol07 ;A25_Pol08 ;A28_Pol09 ;A47_Pol15 ;

### 4.2. Sample 1b: items per entity
#cor(Sample.1b.pol, y = Scores.socdes.b, use = "everything", method = "spearman")
COR <- cbind(Sample.1b.pol, Scores.socdes.b)
COR <- rcorr(as.matrix(COR), type="spearman") # type can be pearson or spearman
cbind(COR$r[16,],COR$P[16,])
```

    ##                         [,1]      [,2]
    ## B33_Pol01       -0.029524495 0.5987505
    ## B34_Pol02       -0.006366072 0.9096855
    ## B35_Pol03       -0.051400801 0.3594082
    ## B36_Pol04        0.056953224 0.3097971
    ## B37_Pol05       -0.052307897 0.3509805
    ## B38_Pol06       -0.048671900 0.3855166
    ## B39_Pol07       -0.028000944 0.6177556
    ## B40_Pol08       -0.060118898 0.2836297
    ## B41_Pol09       -0.042117136 0.4527736
    ## B42_Pol10       -0.006017817 0.9146068
    ## B43_Pol11       -0.041196334 0.4627230
    ## B44_Pol12       -0.011517059 0.8373971
    ## B45_Pol13       -0.010857594 0.8465892
    ## B46_Pol14        0.012192534 0.8280048
    ## B47_Pol15       -0.004094357 0.9418413
    ## Scores.socdes.b  1.000000000        NA

``` r
subset(cbind(COR$r[16,],COR$P[16,]), COR$P[16,] < 0.0500000)# the set of items that should be deleted
```

    ##      [,1] [,2]

``` r
#DELETE: none
```

In this step, two samples were analyzed to evaluate item quality based
on the following three criteria: (1) item-scale correlation, (2) item
consistency with other items, and (3) social desirability of items.

### Design and data collection

In the first wave of data collection, 700 MTurk workers in the U.S.
completed a a questionnaire that would take 10 minutes to complete.
Respondents were rewarded with 1.75 U.S. dollars. This is about 10.50
U.S. dollars per hour, which is in line with the call for stronger
ethical standards on crowd sourcing workforces ([Guidelines for Academic
Requesters](http://www.wearedynamo.org/Guidelines_for_Academic_Requesters.pdf)).
However, the compensation was dependent on the fact whether respondents
answered basic attention questions correctly throughout the survey. It
had been clarified in the assignment to the MTurk workers that payments
would be dependent on correctly answering those attention questions.

Data was collected through the means of a Qualtrics survey. Respondents
were randomly assigned to one of the two survey streams, which were both
analyzed in this study as distinct samples. In one stream, all the 45
items were randomly shuffled and presented in three randomly ordered
batches. Hence, in this stream, all the items for all the three scales
were asked in a combined manner, and each respondent answered them in
different orders. In the second stream, items were grouped as per
entity, and thereby, each batch of 15 items focused respectively on the
attitudes towards the public sector, the public servants, and the
politicians. However, the items within these entity-focused batches
where randomized, and the batch order was also randomized (all with the
Qualtrics randomization functionality). As has been shown by a
substantial body of literature, question order can influence the
response behavior (Van de Walle and Van Ryzin 2011), the randomization
of items and batches attempts to reduce consistent biases in answering
in the data. This structure also allows analysis of the extent to which
item and scale relatedness are influenced by item order. This is further
explored in Step 4 of this analysis. In each batch of 15 items, a
sixteenth item was added that contained an attention question, such as
‘Answer Strongly Disagree here’ or ‘Answer the middle option here’.

For both the survey streams, the questionnaire was finished with a
10-item construct to measure social desirability (Strahan and Gerbasi
1972) and a set of demographic questions on gender, age, employment
status, and education. The construct of social desirability contains
items that invoke answering in a socially desirable manner, which means
that these items were answered by most people to conform to the social
norms rather than represent real behavior and opinions. Including such a
scale enabled testing the extent to which new scale items were
potentially influenced by a social desirability bias (Fischer and Fick
1993). It is, therefore, a common step in the process of scale
validation to delete items that have a strong correlation with a measure
of social desirability. By omitting these items, the overall scale is
less susceptible to social desirability biases in the responses. Strahan
and Gerbasi (1972) developed two interchangeable scales, each containing
ten items. For the first wave of data collection, the first set of 10
items is used, while the second data collection of this study contained
the second set of 10 items. Cronbach’s alpha values for Samples 1 and 2
are 0.81 and 0.83 respectively.

### Results

In total, 709 respondents started, out of which 702 finished the
questionnaire. For 351 respondents, all items of the three constructs
were shuffled (325 answered all attention questions correctly), and the
remaining 351 were presented with categorized blocks of items (320
answered all attention questions correctly). Thus, a relatively low
number of respondents were determined to not be paying sufficient
attention while they completed the questionnaire.

``` r
summary(Sample.Demographics)
```

    ##    Birthyear       English        Occupation     Education    
    ##  Min.   :1943   Min.   :1.000   Min.   :1.00   Min.   :0.000  
    ##  1st Qu.:1976   1st Qu.:1.000   1st Qu.:2.00   1st Qu.:2.000  
    ##  Median :1984   Median :1.000   Median :2.00   Median :3.000  
    ##  Mean   :1981   Mean   :1.009   Mean   :2.42   Mean   :2.452  
    ##  3rd Qu.:1990   3rd Qu.:1.000   3rd Qu.:3.00   3rd Qu.:3.000  
    ##  Max.   :1998   Max.   :2.000   Max.   :6.00   Max.   :4.000

``` r
summary(Sample.Demographics.emp)
```

    ##  Org_Experience      Org_Type        Org_Size   
    ##  Min.   : 1.000   Min.   :1.000   Min.   : 1.0  
    ##  1st Qu.: 4.000   1st Qu.:1.000   1st Qu.: 2.0  
    ##  Median : 6.000   Median :1.000   Median : 3.0  
    ##  Mean   : 7.257   Mean   :1.879   Mean   : 3.6  
    ##  3rd Qu.: 9.000   3rd Qu.:1.000   3rd Qu.: 5.0  
    ##  Max.   :42.000   Max.   :9.000   Max.   :10.0

Several items were deleted since they either had low correlation with
the overall set of items for their respective category (cut-off of 0.4)
and/or because their deletion would increase the reliability of the set
of remaining items. The deleted items were: PubSec15, PubServ03,
PubServ05, PubServ13, Pol04, Pol05, Pol12, and Pol14. The following
items had significant correlations with the social desirability
construct and were, therefore, also deleted: PubSec10, PubSec13,
PubServ02, PubServ03, Pol02, Pol05, Pol07, Pol08, Pol09, Pol15. However,
it must be said that these items did not all correlate consistently with
the social desirability for both samples. So, it is hard to conclude
that some items were consistently biased by social desirability. The
final reliability measures for the reduced scales all met the
traditional criterion of 0.7.

``` r
it.Sample.1a.PubSec$rely$alpha$total
```

    ##  raw_alpha std.alpha   G6(smc) average_r      S/N  median_r
    ##  0.8832026 0.8832026 0.9091167 0.3865607 7.561836 0.3812092

``` r
it.Sample.1b.PubSec$rely$alpha$total
```

    ##  raw_alpha std.alpha   G6(smc) average_r      S/N  median_r
    ##  0.9113211 0.9113211 0.9272914  0.461319 10.27663 0.4771751

``` r
it.Sample.1a.PubServ$rely$alpha$total
```

    ##  raw_alpha std.alpha   G6(smc) average_r      S/N  median_r
    ##  0.9021843 0.9021843 0.9143431  0.456073 9.223304 0.4591584

``` r
it.Sample.1b.PubServ$rely$alpha$total
```

    ##  raw_alpha std.alpha   G6(smc) average_r      S/N  median_r
    ##  0.9242601 0.9242601 0.9324208  0.525925 12.20308 0.5119448

``` r
it.Sample.1a.pol$rely$alpha$total
```

    ##  raw_alpha std.alpha  G6(smc) average_r      S/N  median_r
    ##  0.8707158 0.8707158 0.872596 0.5288536 6.734894 0.5043537

``` r
it.Sample.1b.pol$rely$alpha$total
```

    ##  raw_alpha std.alpha   G6(smc) average_r      S/N  median_r
    ##  0.8863616 0.8863616 0.8848962 0.5652125 7.799845 0.5562125

``` r
it.Sample.1b.socdes$rely$alpha$total
```

    ##  raw_alpha std.alpha   G6(smc) average_r      S/N  median_r
    ##  0.8296723 0.8296723 0.8381147 0.3275519 4.871036 0.3346644

Step 3: Analysis of a third sample to assess relatedness with other public management constructs (convergent and discriminant validity)
---------------------------------------------------------------------------------------------------------------------------------------

``` r
#Download data here: https://osf.io/xky93/  
Sample.2 <- read.csv("DATA/ScalePublicServAttitudes(SAMPLE 3).csv", header = TRUE, sep = ",")
n_started.2 <- nrow(Sample.2)

# Deleting respondents that did not finish questionnaire
Sample.2  <-subset(Sample.2, V10 == 1)   #'V10' is the variable from the Qualtrics output that indicates wheter a respondent answered untill the last page.
n_finished.2 <- nrow(Sample.2)

# Deleting respondents that did not answer all three attention questions in their stream correctly.
Sample.2 <-subset(Sample.2, B16 == -3 & B32 == +3 & B48 == 0 & PSM_17_CONTROL == 1 )
n_sample.2 <- nrow(Sample.2)


Sample.Demographics.2 <-subset(Sample.2, select = c("Birthyear","Occupation","Education"))
Sample.Demographics.emp.2 <-subset(Sample.2 , Org_intro == 1, select = c("Org_Experience" , "Org_Type" , "Org_Size" ))
```

``` r
#### Separate constructs
##### Attitudes towards the Public Sector
Sample.2.PubSec <-subset(Sample.2, select = c("PubSec01" , "PubSec02" , "PubSec03" , "PubSec04" , "PubSec05" , "PubSec06"  , "PubSec07"  , "PubSec08"  , "PubSec09"  ,  "PubSec11" ,  "PubSec12" ,    "PubSec14"))
Scale.Sample.2.PubSec <- Scale(data = Sample.2.PubSec, reverse = c("PubSec04", "PubSec06", "PubSec07", "PubSec09", "PubSec11", "PubSec12"))
prep.Sample.2.PubSec <- PreProc(Scale.Sample.2.PubSec)
it.Sample.2.PubSec <- ItemAnalysis(prep.Sample.2.PubSec, method="spearman", fm="gls", nfactors=1, rcut= 0.4, score_type="z", exclude=c())
it.Sample.2.PubSec
```

    ## 
    ## Reliability Analysis of prep.Sample.2.PubSec ScaleData object. 
    ## 
    ## A spearman correlation matrix of 12 items was calculated and submitted to Reliability analysis.
    ##       
    ## The overall Cronbach's Alpha was 0.92 .
    ## A gls factor analysis was conducted. Items were regressed to
    ##       a single factor. Their loadings are the following:
    ##  PubSec02  PubSec04  PubSec01  PubSec11  PubSec07  PubSec09  PubSec14 
    ## 0.6346341 0.6400568 0.6424975 0.6432362 0.6685866 0.6735144 0.7008099 
    ##  PubSec03  PubSec06  PubSec05  PubSec12  PubSec08 
    ## 0.7191143 0.7452505 0.7648513 0.7678034 0.7904433

``` r
Att.Pub.Sector <- -((Sample.2.PubSec$PubSec01 + Sample.2.PubSec$PubSec02 + Sample.2.PubSec$PubSec03 - Sample.2.PubSec$PubSec04 + Sample.2.PubSec$PubSec05 - Sample.2.PubSec$PubSec06  - Sample.2.PubSec$PubSec07  + Sample.2.PubSec$PubSec08  - Sample.2.PubSec$PubSec09  -  Sample.2.PubSec$PubSec11 -  Sample.2.PubSec$PubSec12 +  Sample.2.PubSec$PubSec14)/12)

##### Attitudes towards the Public Servants
Sample.2.PubServ <-subset(Sample.2, select = c("PubServ01", "PubServ04" , "PubServ06" , "PubServ07" ,  "PubServ08",  "PubServ09", "PubServ10" , "PubServ11" , "PubServ12" , "PubServ14", "PubServ15"))
Scale.Sample.2.PubServ <- Scale(data = Sample.2.PubServ, reverse = c("PubServ06", "PubServ10", "PubServ14", "PubServ15"))
prep.Sample.2.PubServ <- PreProc(Scale.Sample.2.PubServ)
it.Sample.2.PubServ <- ItemAnalysis(prep.Sample.2.PubServ, method="spearman", fm="gls", nfactors=1, rcut= 0.4, score_type="z", exclude=c())
it.Sample.2.PubServ
```

    ## 
    ## Reliability Analysis of prep.Sample.2.PubServ ScaleData object. 
    ## 
    ## A spearman correlation matrix of 11 items was calculated and submitted to Reliability analysis.
    ##       
    ## The overall Cronbach's Alpha was 0.92 .
    ## Furthermore, deleting item(s) 2 may improve reliability.A gls factor analysis was conducted. Items were regressed to
    ##       a single factor. Their loadings are the following:
    ## PubServ04 PubServ15 PubServ14 PubServ06 PubServ09 PubServ10 PubServ08 
    ## 0.4697289 0.5824474 0.6255183 0.7348585 0.7607155 0.7667142 0.7721853 
    ## PubServ11 PubServ12 PubServ07 PubServ01 
    ## 0.7776011 0.7819261 0.8416815 0.8434547

``` r
Att.Pub.Servants <- -(Sample.2.PubServ$PubServ01+Sample.2.PubServ$PubServ04-Sample.2.PubServ$PubServ06+Sample.2.PubServ$PubServ07+Sample.2.PubServ$PubServ08+Sample.2.PubServ$PubServ09-Sample.2.PubServ$PubServ10+Sample.2.PubServ$PubServ11+Sample.2.PubServ$PubServ12-Sample.2.PubServ$PubServ14-Sample.2.PubServ$PubServ15)/11

##### Attitudes towards the Politicians
Sample.2.pol <-subset(Sample.2, select = c("Pol01" , "Pol03",  "Pol06" ,  "Pol10" , "Pol11" ,  "Pol13"  ))
Scale.Sample.2.pol <- Scale(data = Sample.2.pol, reverse = c("Pol06" ,  "Pol10"))
prep.Sample.2.pol <- PreProc(Scale.Sample.2.pol)
it.Sample.2.pol <- ItemAnalysis(prep.Sample.2.pol, method="spearman" , fm="gls", nfactors=1, rcut= 0.4, score_type="z", exclude=c())
it.Sample.2.pol
```

    ## 
    ## Reliability Analysis of prep.Sample.2.pol ScaleData object. 
    ## 
    ## A spearman correlation matrix of 6 items was calculated and submitted to Reliability analysis.
    ##       
    ## The overall Cronbach's Alpha was 0.88 .
    ## Furthermore, deleting item(s) 3 may improve reliability.A gls factor analysis was conducted. Items were regressed to
    ##       a single factor. Their loadings are the following:
    ##     Pol06     Pol10     Pol13     Pol11     Pol01     Pol03 
    ## 0.4057458 0.6733973 0.8081177 0.8521745 0.8685449 0.8984076

``` r
Att.Politicians <- -(Sample.2.pol$Pol01+Sample.2.pol$Pol03-Sample.2.pol$Pol06-Sample.2.pol$Pol10+Sample.2.pol$Pol11+Sample.2.pol$Pol13)/6

##### PSM-Short [@Vandenabeele2016a]
Sample.2.PSM_Short <-subset(Sample.2, select = c("PSM_Short_1" , "PSM_Short_2" , "PSM_Short_3" , "PSM_Short_4"))
Scale.Sample.2.PSM_Short <- Scale(data = Sample.2.PSM_Short, reverse = c())
prep.Sample.2.PSM_Short <- PreProc(Scale.Sample.2.PSM_Short)
it.Sample.2.PSM_Short <- ItemAnalysis(prep.Sample.2.PSM_Short, method="spearman", fm="gls", nfactors=1, rcut= 0.4, score_type="z", exclude=c()) 
it.Sample.2.PSM_Short
```

    ## 
    ## Reliability Analysis of prep.Sample.2.PSM_Short ScaleData object. 
    ## 
    ## A spearman correlation matrix of 4 items was calculated and submitted to Reliability analysis.
    ##       
    ## The overall Cronbach's Alpha was 0.92 .
    ## Furthermore, deleting item(s) 4 may improve reliability.A gls factor analysis was conducted. Items were regressed to
    ##       a single factor. Their loadings are the following:
    ## PSM_Short_4 PSM_Short_1 PSM_Short_3 PSM_Short_2 
    ##   0.7611785   0.9063724   0.9094685   0.9126267

``` r
PSM_Short <- (Sample.2$PSM_Short_1+Sample.2$PSM_Short_2+Sample.2$PSM_Short_3+Sample.2$PSM_Short_4)/4

##### PSM [@Kim2013a]

Sample.2.PSM <-subset(Sample.2, select = c("PSM_1_APP5" , "PSM_2_APP7" , "PSM_3_CPI1" , "PSM_4_CPI2" , "PSM_5_CPV1" , "PSM_6_CPV2" , "PSM_7_CPV6" , "PSM_8_CPV7" , "PSM_9_COM2" , "PSM_10_COM3" , "PSM_11_COM5" , "PSM_12_COM6" , "PSM_13_SS2" , "PSM_14_SS3" , "PSM_15_SS4" , "PSM_16_SS7"))
Scale.Sample.2.PSM <- Scale(data = Sample.2.PSM, reverse = c())
prep.Sample.2.PSM <- PreProc(Scale.Sample.2.PSM)
it.Sample.2.PSM <- ItemAnalysis(prep.Sample.2.PSM, method="spearman", fm="gls", nfactors=1, rcut= 0.4, score_type="z", exclude=c()) 
it.Sample.2.PSM
```

    ## 
    ## Reliability Analysis of prep.Sample.2.PSM ScaleData object. 
    ## 
    ## A spearman correlation matrix of 16 items was calculated and submitted to Reliability analysis.
    ##       
    ## The overall Cronbach's Alpha was 0.93 .
    ## Furthermore, deleting item(s) 8 may improve reliability.A gls factor analysis was conducted. Items were regressed to
    ##       a single factor. Their loadings are the following:
    ##  PSM_8_CPV7  PSM_14_SS3  PSM_6_CPV2  PSM_15_SS4  PSM_7_CPV6  PSM_5_CPV1 
    ##   0.5123649   0.5413909   0.6086392   0.6125440   0.6646198   0.6710072 
    ##  PSM_1_APP5  PSM_3_CPI1  PSM_13_SS2 PSM_11_COM5  PSM_16_SS7  PSM_9_COM2 
    ##   0.6909648   0.6946126   0.6956451   0.7071396   0.7197568   0.7431360 
    ## PSM_12_COM6 PSM_10_COM3  PSM_4_CPI2  PSM_2_APP7 
    ##   0.7716201   0.7795097   0.7832809   0.7834485

``` r
PSM <- (Sample.2$PSM_1_APP5 + Sample.2$PSM_2_APP7 + Sample.2$PSM_3_CPI1 + Sample.2$PSM_4_CPI2 + Sample.2$PSM_5_CPV1 + Sample.2$PSM_6_CPV2 + Sample.2$PSM_7_CPV6 + Sample.2$PSM_8_CPV7 + Sample.2$PSM_9_COM2 + Sample.2$PSM_10_COM3 + Sample.2$PSM_11_COM5 + Sample.2$PSM_12_COM6 + Sample.2$PSM_13_SS2 + Sample.2$PSM_14_SS3 + Sample.2$PSM_15_SS4 + Sample.2$PSM_16_SS7)/16

model.4dim.PSM <- '
APS =~ PSM_1_APP5 + PSM_2_APP7 + PSM_3_CPI1 + PSM_4_CPI2 
CPV =~  PSM_5_CPV1 + PSM_6_CPV2 + PSM_7_CPV6 + PSM_8_CPV7 
COM =~ PSM_9_COM2 + PSM_10_COM3 + PSM_11_COM5 + PSM_12_COM6 
SS  =~  PSM_13_SS2 + PSM_14_SS3 + PSM_15_SS4 + PSM_16_SS7
'
fit.4dim.PSM <- cfa(model.4dim.PSM, data = Sample.2.PSM)
summary(fit.4dim.PSM, header=TRUE, standardized=TRUE, fit.measures=TRUE,estimates = FALSE,modindices = FALSE, ci=FALSE, rsquare=FALSE)
```

    ## lavaan 0.6-4 ended normally after 51 iterations
    ## 
    ##   Optimization method                           NLMINB
    ##   Number of free parameters                         38
    ## 
    ##   Number of observations                           337
    ## 
    ##   Estimator                                         ML
    ##   Model Fit Test Statistic                     297.643
    ##   Degrees of freedom                                98
    ##   P-value (Chi-square)                           0.000
    ## 
    ## Model test baseline model:
    ## 
    ##   Minimum Function Test Statistic             3390.005
    ##   Degrees of freedom                               120
    ##   P-value                                        0.000
    ## 
    ## User model versus baseline model:
    ## 
    ##   Comparative Fit Index (CFI)                    0.939
    ##   Tucker-Lewis Index (TLI)                       0.925
    ## 
    ## Loglikelihood and Information Criteria:
    ## 
    ##   Loglikelihood user model (H0)              -5547.492
    ##   Loglikelihood unrestricted model (H1)      -5398.670
    ## 
    ##   Number of free parameters                         38
    ##   Akaike (AIC)                               11170.983
    ##   Bayesian (BIC)                             11316.146
    ##   Sample-size adjusted Bayesian (BIC)        11195.605
    ## 
    ## Root Mean Square Error of Approximation:
    ## 
    ##   RMSEA                                          0.078
    ##   90 Percent Confidence Interval          0.068  0.088
    ##   P-value RMSEA <= 0.05                          0.000
    ## 
    ## Standardized Root Mean Square Residual:
    ## 
    ##   SRMR                                           0.051

``` r
###### PSM-APS [@Kim2013a]
Sample.2.PSM_APS <-subset(Sample.2, select = c("PSM_1_APP5" , "PSM_2_APP7" , "PSM_3_CPI1" , "PSM_4_CPI2" ))
Scale.Sample.2.PSM_APS <- Scale(data = Sample.2.PSM_APS, reverse = c())
prep.Sample.2.PSM_APS <- PreProc(Scale.Sample.2.PSM_APS)
it.Sample.2.PSM_APS <- ItemAnalysis(prep.Sample.2.PSM_APS, method="spearman", fm="gls", nfactors=1, rcut= 0.4, score_type="z", exclude=c()) 
it.Sample.2.PSM_APS
```

    ## 
    ## Reliability Analysis of prep.Sample.2.PSM_APS ScaleData object. 
    ## 
    ## A spearman correlation matrix of 4 items was calculated and submitted to Reliability analysis.
    ##       
    ## The overall Cronbach's Alpha was 0.84 .
    ## A gls factor analysis was conducted. Items were regressed to
    ##       a single factor. Their loadings are the following:
    ## PSM_1_APP5 PSM_3_CPI1 PSM_2_APP7 PSM_4_CPI2 
    ##  0.6683398  0.7570684  0.7948911  0.8137199

``` r
PSM_APS <- (Sample.2$PSM_1_APP5 + Sample.2$PSM_2_APP7 + Sample.2$PSM_3_CPI1 + Sample.2$PSM_4_CPI2)/4

###### PSM-CPV [@Kim2013a]
Sample.2.PSM_CPV <-subset(Sample.2, select = c("PSM_5_CPV1" , "PSM_6_CPV2" , "PSM_7_CPV6" , "PSM_8_CPV7"))
Scale.Sample.2.PSM_CPV <- Scale(data = Sample.2.PSM_CPV, reverse = c())
prep.Sample.2.PSM_CPV <- PreProc(Scale.Sample.2.PSM_CPV)
it.Sample.2.PSM_CPV <- ItemAnalysis(prep.Sample.2.PSM_CPV, method="spearman", fm="gls", nfactors=1, rcut= 0.4, score_type="z", exclude=c()) 
it.Sample.2.PSM_CPV
```

    ## 
    ## Reliability Analysis of prep.Sample.2.PSM_CPV ScaleData object. 
    ## 
    ## A spearman correlation matrix of 4 items was calculated and submitted to Reliability analysis.
    ##       
    ## The overall Cronbach's Alpha was 0.79 .
    ## A gls factor analysis was conducted. Items were regressed to
    ##       a single factor. Their loadings are the following:
    ## PSM_8_CPV7 PSM_6_CPV2 PSM_7_CPV6 PSM_5_CPV1 
    ##  0.6574397  0.6845589  0.7137437  0.7477211

``` r
PSM_CPV <- (Sample.2$PSM_5_CPV1 + Sample.2$PSM_6_CPV2 + Sample.2$PSM_7_CPV6 + Sample.2$PSM_8_CPV7)/4

###### PSM-COM  [@Kim2013a]
Sample.2.PSM_COM <-subset(Sample.2, select = c("PSM_9_COM2" , "PSM_10_COM3" , "PSM_11_COM5" , "PSM_12_COM6"))
Scale.Sample.2.PSM_COM <- Scale(data = Sample.2.PSM_COM, reverse = c())
prep.Sample.2.PSM_COM <- PreProc(Scale.Sample.2.PSM_COM)
it.Sample.2.PSM_COM <- ItemAnalysis(prep.Sample.2.PSM_COM, method="spearman", fm="gls", nfactors=1, rcut= 0.4, score_type="z", exclude=c()) 
it.Sample.2.PSM_COM
```

    ## 
    ## Reliability Analysis of prep.Sample.2.PSM_COM ScaleData object. 
    ## 
    ## A spearman correlation matrix of 4 items was calculated and submitted to Reliability analysis.
    ##       
    ## The overall Cronbach's Alpha was 0.87 .
    ## A gls factor analysis was conducted. Items were regressed to
    ##       a single factor. Their loadings are the following:
    ## PSM_11_COM5 PSM_12_COM6  PSM_9_COM2 PSM_10_COM3 
    ##   0.7456694   0.7607714   0.7859500   0.8682152

``` r
PSM_COM <- (Sample.2$PSM_9_COM2+Sample.2$PSM_10_COM3+Sample.2$PSM_11_COM5+Sample.2$PSM_12_COM6)/4

###### PSM-SS  [@Kim2013a]
Sample.2.PSM_SS <-subset(Sample.2, select = c("PSM_13_SS2" , "PSM_14_SS3" , "PSM_15_SS4" , "PSM_16_SS7"))
Scale.Sample.2.PSM_SS <- Scale(data = Sample.2.PSM_SS, reverse = c())
prep.Sample.2.PSM_SS <- PreProc(Scale.Sample.2.PSM_SS)
it.Sample.2.PSM_SS <- ItemAnalysis(prep.Sample.2.PSM_SS, method="spearman", fm="gls", nfactors=1, rcut= 0.4, score_type="z", exclude=c()) 
it.Sample.2.PSM_SS
```

    ## 
    ## Reliability Analysis of prep.Sample.2.PSM_SS ScaleData object. 
    ## 
    ## A spearman correlation matrix of 4 items was calculated and submitted to Reliability analysis.
    ##       
    ## The overall Cronbach's Alpha was 0.84 .
    ## Furthermore, deleting item(s) 2 may improve reliability.A gls factor analysis was conducted. Items were regressed to
    ##       a single factor. Their loadings are the following:
    ## PSM_14_SS3 PSM_16_SS7 PSM_15_SS4 PSM_13_SS2 
    ##  0.6277102  0.7306476  0.8204936  0.8582121

``` r
PSM_SS <- (Sample.2$PSM_13_SS2+Sample.2$PSM_14_SS3+Sample.2$PSM_15_SS4+Sample.2$PSM_16_SS7)/4

##### Government Trust (based on @Grimmelikhuijsen2017a)
Sample.2.GovTrust <-subset(Sample.2, select = c("GovTrust_1_Comp1" , "GovTrust_2_Comp4" , "GovTrust_3_Comp5" , "GovTrust_4_Ben1" , "GovTrust_5_Ben2" , "GovTrust_6_Ben3" , "GovTrust_7_Int1" , "GovTrust_8_Int2" , "GovTrust_9_Int4"))
Scale.Sample.2.GovTrust <- Scale(data = Sample.2.GovTrust, reverse = c())
prep.Sample.2.GovTrust <- PreProc(Scale.Sample.2.GovTrust)
it.Sample.2.GovTrust <- ItemAnalysis(prep.Sample.2.GovTrust, method="spearman", fm="gls", nfactors=1, rcut= 0.4, score_type="z", exclude=c()) 
it.Sample.2.GovTrust
```

    ## 
    ## Reliability Analysis of prep.Sample.2.GovTrust ScaleData object. 
    ## 
    ## A spearman correlation matrix of 9 items was calculated and submitted to Reliability analysis.
    ##       
    ## The overall Cronbach's Alpha was 0.95 .
    ## Furthermore, deleting item(s) 1 may improve reliability.A gls factor analysis was conducted. Items were regressed to
    ##       a single factor. Their loadings are the following:
    ## GovTrust_1_Comp1 GovTrust_2_Comp4 GovTrust_3_Comp5  GovTrust_4_Ben1 
    ##        0.6609668        0.7490076        0.8542833        0.8560258 
    ##  GovTrust_9_Int4  GovTrust_8_Int2  GovTrust_7_Int1  GovTrust_5_Ben2 
    ##        0.8573065        0.8643762        0.8703071        0.8947237 
    ##  GovTrust_6_Ben3 
    ##        0.8995178

``` r
Gov.Trust <- (Sample.2$GovTrust_1_Comp1 + Sample.2$GovTrust_2_Comp4 + Sample.2$GovTrust_3_Comp5 + Sample.2$GovTrust_4_Ben1 + Sample.2$GovTrust_5_Ben2 + Sample.2$GovTrust_6_Ben3 + Sample.2$GovTrust_7_Int1 + Sample.2$GovTrust_8_Int2 + Sample.2$GovTrust_9_Int4)/9

#same numbering/naming of items as @Grimmelikhuijsen2017a is used 
model.3dim.GovTrust <- ' 
COMP =~ GovTrust_1_Comp1+GovTrust_2_Comp4+GovTrust_3_Comp5
BEN =~ GovTrust_4_Ben1+GovTrust_5_Ben2+GovTrust_6_Ben3
INT =~ GovTrust_7_Int1+GovTrust_8_Int2+GovTrust_9_Int4 ' 
fit.3dim.GovTrust <- cfa(model.3dim.GovTrust, data = Sample.2.GovTrust)
summary(fit.3dim.GovTrust, header=TRUE, standardized=TRUE, fit.measures=TRUE,estimates = FALSE, modindices = FALSE, ci=FALSE, rsquare=FALSE)
```

    ## lavaan 0.6-4 ended normally after 44 iterations
    ## 
    ##   Optimization method                           NLMINB
    ##   Number of free parameters                         21
    ## 
    ##   Number of observations                           337
    ## 
    ##   Estimator                                         ML
    ##   Model Fit Test Statistic                      28.650
    ##   Degrees of freedom                                24
    ##   P-value (Chi-square)                           0.234
    ## 
    ## Model test baseline model:
    ## 
    ##   Minimum Function Test Statistic             2843.708
    ##   Degrees of freedom                                36
    ##   P-value                                        0.000
    ## 
    ## User model versus baseline model:
    ## 
    ##   Comparative Fit Index (CFI)                    0.998
    ##   Tucker-Lewis Index (TLI)                       0.998
    ## 
    ## Loglikelihood and Information Criteria:
    ## 
    ##   Loglikelihood user model (H0)              -3158.003
    ##   Loglikelihood unrestricted model (H1)      -3143.678
    ## 
    ##   Number of free parameters                         21
    ##   Akaike (AIC)                                6358.007
    ##   Bayesian (BIC)                              6438.229
    ##   Sample-size adjusted Bayesian (BIC)         6371.614
    ## 
    ## Root Mean Square Error of Approximation:
    ## 
    ##   RMSEA                                          0.024
    ##   90 Percent Confidence Interval          0.000  0.052
    ##   P-value RMSEA <= 0.05                          0.929
    ## 
    ## Standardized Root Mean Square Residual:
    ## 
    ##   SRMR                                           0.014

``` r
#By changing some of the paramaters to 'true', more info is provided

##### Government Trust-Competence (based on @Grimmelikhuijsen2017a)
Sample.2.GovTrust_Comp <-subset(Sample.2, select = c("GovTrust_1_Comp1" , "GovTrust_2_Comp4" , "GovTrust_3_Comp5"))
Scale.Sample.2.GovTrust_Comp <- Scale(data = Sample.2.GovTrust_Comp, reverse = c())
prep.Sample.2.GovTrust_Comp <- PreProc(Scale.Sample.2.GovTrust_Comp)
it.Sample.2.GovTrust_Comp <- ItemAnalysis(prep.Sample.2.GovTrust_Comp, method="spearman", fm="gls", nfactors=1, rcut= 0.4, score_type="z", exclude=c()) 
it.Sample.2.GovTrust_Comp
```

    ## 
    ## Reliability Analysis of prep.Sample.2.GovTrust_Comp ScaleData object. 
    ## 
    ## A spearman correlation matrix of 3 items was calculated and submitted to Reliability analysis.
    ##       
    ## The overall Cronbach's Alpha was 0.85 .
    ## A gls factor analysis was conducted. Items were regressed to
    ##       a single factor. Their loadings are the following:
    ## GovTrust_1_Comp1 GovTrust_2_Comp4 GovTrust_3_Comp5 
    ##        0.7361178        0.8254259        0.8546284

``` r
Gov.Trust.Comp <- (Sample.2$GovTrust_1_Comp1 + Sample.2$GovTrust_2_Comp4 + Sample.2$GovTrust_3_Comp5 )/3

##### Government Trust-Benevolence (based on @Grimmelikhuijsen2017a)
Sample.2.GovTrust_Ben <-subset(Sample.2, select = c("GovTrust_4_Ben1" , "GovTrust_5_Ben2" , "GovTrust_6_Ben3"))
Scale.Sample.2.GovTrust_Ben <- Scale(data = Sample.2.GovTrust_Ben, reverse = c())
prep.Sample.2.GovTrust_Ben <- PreProc(Scale.Sample.2.GovTrust_Ben)
it.Sample.2.GovTrust_Ben <- ItemAnalysis(prep.Sample.2.GovTrust_Ben, method="spearman", fm="gls", nfactors=1, rcut= 0.4, score_type="z", exclude=c()) 
it.Sample.2.GovTrust_Ben
```

    ## 
    ## Reliability Analysis of prep.Sample.2.GovTrust_Ben ScaleData object. 
    ## 
    ## A spearman correlation matrix of 3 items was calculated and submitted to Reliability analysis.
    ##       
    ## The overall Cronbach's Alpha was 0.92 .
    ## A gls factor analysis was conducted. Items were regressed to
    ##       a single factor. Their loadings are the following:
    ## GovTrust_4_Ben1 GovTrust_6_Ben3 GovTrust_5_Ben2 
    ##       0.8762568       0.8845293       0.9203206

``` r
Gov.Trust.Ben <- ( Sample.2$GovTrust_4_Ben1 + Sample.2$GovTrust_5_Ben2 + Sample.2$GovTrust_6_Ben3 )/3

##### Government Trust-Integrity (based on @Grimmelikhuijsen2017a)
Sample.2.GovTrust_Int <-subset(Sample.2, select = c("GovTrust_7_Int1" , "GovTrust_8_Int2" , "GovTrust_9_Int4"))
Scale.Sample.2.GovTrust_Int <- Scale(data = Sample.2.GovTrust_Int, reverse = c())
prep.Sample.2.GovTrust_Int <- PreProc(Scale.Sample.2.GovTrust_Int)
it.Sample.2.GovTrust_Int <- ItemAnalysis(prep.Sample.2.GovTrust_Int, method="spearman", fm="gls", nfactors=1, rcut= 0.4, score_type="z", exclude=c()) 
it.Sample.2.GovTrust_Int
```

    ## 
    ## Reliability Analysis of prep.Sample.2.GovTrust_Int ScaleData object. 
    ## 
    ## A spearman correlation matrix of 3 items was calculated and submitted to Reliability analysis.
    ##       
    ## The overall Cronbach's Alpha was 0.92 .
    ## A gls factor analysis was conducted. Items were regressed to
    ##       a single factor. Their loadings are the following:
    ## GovTrust_9_Int4 GovTrust_8_Int2 GovTrust_7_Int1 
    ##       0.8783104       0.8960933       0.9037073

``` r
Gov.Trust.Int <- (Sample.2$GovTrust_7_Int1 + Sample.2$GovTrust_8_Int2 + Sample.2$GovTrust_9_Int4)/3

#### NES
Sample.2.NES <-subset(Sample.2, select = c( "NES1_1", "NES2_1", "NES3_1", "NES4_1"))
Scale.Sample.2.NES <- Scale(data = Sample.2.NES, reverse = c())
prep.Sample.2.NES <- PreProc(Scale.Sample.2.NES)
it.Sample.2.NES <- ItemAnalysis(prep.Sample.2.NES, method="spearman", fm="gls", nfactors=1, rcut= 0.4, score_type="z", exclude=c()) 
it.Sample.2.NES
```

    ## 
    ## Reliability Analysis of prep.Sample.2.NES ScaleData object. 
    ## 
    ## A spearman correlation matrix of 4 items was calculated and submitted to Reliability analysis.
    ##       
    ## The overall Cronbach's Alpha was 0.87 .
    ## A gls factor analysis was conducted. Items were regressed to
    ##       a single factor. Their loadings are the following:
    ##    NES3_1    NES1_1    NES2_1    NES4_1 
    ## 0.7314592 0.7598689 0.8160586 0.8489043

``` r
Gov.Trust.NES <- (Sample.2$NES1_1+Sample.2$NES2_1+Sample.2$NES3_1+Sample.2$NES4_1)/4

#### Sectors Trust
Sample.2.SecTrust <-subset(Sample.2, select = c( "SectorsTrust_1_Bus", "SectorsTrust_4_Gov", "SectorsTrust_5_NonProfit"))
Scale.Sample.2.SecTrust <- Scale(data = Sample.2.SecTrust, reverse = c())
prep.Sample.2.SecTrust <- PreProc(Scale.Sample.2.SecTrust)
it.Sample.2.SecTrust <- ItemAnalysis(prep.Sample.2.SecTrust, method="spearman", fm="gls", nfactors=1, rcut= 0.4, score_type="z", exclude=c()) 
it.Sample.2.SecTrust
```

    ## 
    ## Reliability Analysis of prep.Sample.2.SecTrust ScaleData object. 
    ## 
    ## A spearman correlation matrix of 3 items was calculated and submitted to Reliability analysis.
    ##       
    ## The overall Cronbach's Alpha was 0.67 .
    ## Furthermore, deleting item(s) 3 may improve reliability.A gls factor analysis was conducted. Items were regressed to
    ##       a single factor. Their loadings are the following:
    ## SectorsTrust_5_NonProfit       SectorsTrust_1_Bus       SectorsTrust_4_Gov 
    ##                0.4589380                0.6331792                0.8420344

``` r
#Make 3 different scales 
SecTrust_Bus <- Sample.2$SectorsTrust_1_Bus
SecTrust_Gov <- Sample.2$SectorsTrust_4_Gov
SecTrust_NonProfit <- Sample.2$SectorsTrust_5_NonProfit
#1-item scale
PubSecFeeling <- Sample.2$PubSecFeel_1 -4

#### Conservative - Liberal
Sample.2.ConsLib <-subset(Sample.2, select = c("Conservative", "Liberal"))
Scale.Sample.2.ConsLib <- Scale(data = Sample.2.ConsLib, reverse = c("Liberal"))
prep.Sample.2.ConsLib <- PreProc(Scale.Sample.2.ConsLib)
it.Sample.2.ConsLib <- ItemAnalysis(prep.Sample.2.ConsLib, method="spearman", fm="gls", nfactors=1, rcut= 0.4, score_type="z", exclude=c()) 
it.Sample.2.ConsLib
```

    ## 
    ## Reliability Analysis of prep.Sample.2.ConsLib ScaleData object. 
    ## 
    ## A spearman correlation matrix of 2 items was calculated and submitted to Reliability analysis.
    ##       
    ## The overall Cronbach's Alpha was 0.86 .
    ## A gls factor analysis was conducted. Items were regressed to
    ##       a single factor. Their loadings are the following:
    ## Conservative      Liberal 
    ##    0.8648885    0.8648885

``` r
Conservative <- (Sample.2$Conservative-Sample.2$Liberal)/2

##### Social Desireabilty II
Sample.2.socdes <-subset(Sample.2, select = c("Social_desirability_1" , "Social_desirability_2" ,"Social_desirability_3" ,"Social_desirability_4" ,"Social_desirability_5" ,"Social_desirability_6" ,"Social_desirability_7" ,"Social_desirability_8" ,"Social_desirability_9" ,"Social_desirability_10"))
Scale.Sample.2.socdes <- Scale(data = Sample.2.socdes, reverse = c("Social_desirability_6" , "Social_desirability_7" ,"Social_desirability_8" ,"Social_desirability_9" ,"Social_desirability_10"))
prep.Sample.2.socdes <- PreProc(Scale.Sample.2.socdes)
it.Sample.2.socdes <- ItemAnalysis(prep.Sample.2.socdes, method="spearman", fm="gls", nfactors=1, rcut= 0.4, score_type="z", exclude=c(2)) 
it.Sample.2.socdes
```

    ## 
    ## Reliability Analysis of prep.Sample.2.socdes ScaleData object. 
    ## 
    ## A spearman correlation matrix of 9 items was calculated and submitted to Reliability analysis.
    ##       
    ## The overall Cronbach's Alpha was 0.8 .
    ## A gls factor analysis was conducted. Items were regressed to
    ##       a single factor. Their loadings are the following:
    ##  Social_desirability_5  Social_desirability_8  Social_desirability_3 
    ##              0.4614606              0.4844951              0.5083725 
    ##  Social_desirability_4  Social_desirability_9  Social_desirability_7 
    ##              0.5878222              0.5878443              0.5931581 
    ##  Social_desirability_1  Social_desirability_6 Social_desirability_10 
    ##              0.5993508              0.6655139              0.6992925

``` r
social.desir <- (Sample.2.socdes$Social_desirability_1 + Sample.2.socdes$Social_desirability_2 + Sample.2.socdes$Social_desirability_3 +Sample.2.socdes$Social_desirability_4 +Sample.2.socdes$Social_desirability_5 -Sample.2.socdes$Social_desirability_6 -Sample.2.socdes$Social_desirability_7 -Sample.2.socdes$Social_desirability_8 -Sample.2.socdes$Social_desirability_9 -Sample.2.socdes$Social_desirability_10)/10
```

``` r
###Correlation analysis
SCORES <- cbind(
Att.Pub.Sector,
Att.Pub.Servants,
Att.Politicians,
PSM_Short,
PSM_APS,
PSM_CPV,
PSM_COM,
PSM_SS,
Gov.Trust.Comp,
Gov.Trust.Ben,
Gov.Trust.Int,
Gov.Trust.NES,
SecTrust_Gov ,
SecTrust_NonProfit ,
SecTrust_Bus, 
PubSecFeeling, 
Conservative,
social.desir)

M <- cor(SCORES)
diag(M) = NA
res1 <- cor.mtest(SCORES, conf.level = .95) # this is necessary to be able to remove non-significant correlations from the table
# write.table(SCORES, "DATA/SCORES.txt", sep="\t") 
```

### Design and data collection

Statistical relatedness with other public management constructs was
evaluated based on a third sample, which was also obtained through
MTurk. In total, 350 respondents were sought from the U.S., leading to a
total of 353 respondents, who started the questionnaire. All 353
respondents finished the questionnaire, among whom 337 answered all the
attention questions correctly. These respondents received a reward of 2
U.S. dollar reward for completing the questionnaire.

The Qualtrics questionnaire contained the three focal constructs having
the remaining items. Cronbach’s alpha values are listed as follows:
public sector: 0.90; public servants: 0.89; politicians: 0.87. The order
of the three attitude pages was randomized for each respondent, and the
item order per scale were randomized as well. Similar to the first wave
of data collection, each scale was accompanied with an attention
question, and respondents who failed to answer all attention questions
correctly were removed from further analysis.

Subsequently, all respondents went through eight additional survey pages
with the following constructs, for which the order was also randomized
for every respondent:

1.  A short version of public service motivation (PSM) (Vandenabeele and
    Vries 2013). Public service motivation is the motivation for people
    to engage in the provision of public goods, and it has been studied
    mainly among public servants (Perry and Wise 1990). Despite the fact
    that PSM research mainly focuses on motivations of this particular
    sub-population, it is relevant amongst a broader population too, as
    it, for example, is used to explain the willingness to choose a job
    in the public sector among non-public servants (Choi 2017; Lee and
    Choi 2016; Wright, Hassan, and Christensen 2017). Hence, it is
    expected to have a certain degree of convergence with the attitude
    scales, especially towards the public sector and the public
    servants. The 4-item shortened version of the scale of Vandenabeele
    and Vries (2013) has been included in this study as an overall,
    summarizing measure of the multi-dimensional construct of PSM.
    Answers could be given on a 7-point Likert scale, ranging from
    strongly disagree (-3) to strongly agree (+3) (alpha = 0.97).

2.  A multi-dimensional measure of PSM (Kim et al. 2013). This is a
    16-item scale having four sub-dimensions, and it was validated based
    on a broad range of samples across the world. The four
    sub-dimensions are as follows: attraction to public service (APS;
    alpha = 0.90), commitment to public values (CPV; alpha = 0.85),
    compassion (COM; alpha = 0.93), and self-sacrifice (SS; alpha =
    0.90). This construct has been included in this study to get an
    additional insight on how the PSM dimensions relate to the three
    attitude scales. Similar to the original scale, answers could be
    given on a 5-point Likert scale, ranging from strongly disagree (-2)
    to strongly agree (+2). A seventeenth item was included as an extra
    attention question for this data collection. Fit indices for the
    confirmatory factor analysis for the overall PSM scale are as
    follows: p-value (Chi-square) &lt; 0.001; CFI = 0.939 ; TLI = 0.925;
    RMSEA = 0.078; p-value for the test that RMSEA is less than or equal
    to 0.05 is less than 0.001; SRMR = 0.051). Despite the fact that not
    all of them are within the strict cut-off boundaries as has been
    proposed by Marsh, Hau, and Wen (2004), they show a fairly good
    model fit and are close to the overall fit indices as reported by
    Kim et al. (2013).

3.  Citizens’ trust in government (Grimmelikhuijsen and Knies 2017).
    This is a 9-item scale having the following three dimensions:
    competence (alpha = 0.93), benevolence (alpha = 0.98), and integrity
    (alpha = 0.98). Government as an abstract entity includes the
    entities of politicians, public services, and public servants.
    Hence, as a general measure, it can clarify how attitudes of these
    entities relate to this overreaching trust measurement.
    Grimmelikhuijsen and Knies (2017) proposes that the focal entity,
    such as a particular municipality, and the specific public task,
    such as air-quality policy, can be varied and added to the list of
    items. Given the overall context of this study and the fact that
    data collection had happened in the U.S., items had been formulated
    to focus on the U.S. government. An example item is: ‘The U.S.
    government carries out its duty very well’. Consistent with the
    original scale, a 5-point Likert scale was used, ranging from
    strongly disagree (-2) to strongly agree (+2). The fit indices for
    the confirmatory factor analysis for the citizens’ trust in
    government scale are as follows: p-value (Chi-square) = 0.23; CFI =
    0.998; TLI = 0.998; RMSEA = 0.024; p-value for test that RMSEA is
    less than or equal to 0.05 is 0.929; SRMR = 0.014). These fit
    indices are similar to, and to some extent even better than, the
    original study that has been conducted by Grimmelikhuijsen and
    Knies (2017). Despite the fact that it is not the purpose of this
    study, this analysis, thus, provides a replication in English, with
    a focus on the overall U.S. government, of their initial study from
    the Netherlands. In contrast to Grimmelikhuijsen and Knies (2017),
    the RMSEA value is within the expected boundaries as postulated by
    Marsh, Hau, and Wen (2004).

4.  Trust in government index. It is a 4-item index of the [American
    National Election
    Studies](http://www.electionstudies.org/nesguide/gd-index.htm), in
    contrast to the original scale, in which 7-answer points were used
    for all four questions and were numbered from 1 to 7. The exact
    answer-option labels of the original 2, 3, or 4-point scales in this
    index were presented on top of the scales and were outlined for the
    width of the scale. By asking all the four items as 7-point scales,
    this scale is more consistent with the other constructs in this
    study, and traditional multi-variate analysis can be used (alpha =
    0.93). The inclusion of this scale provides an alternative measure
    of trust in the overreaching government category.

5.  Trust in sector organizations (Bader 2016; McDougle 2014). This is a
    construct that focuses on the trust that respondents have on the
    people working in different sectors. It is not a multi-item
    construct, but each of the items focus on a specific entity and are
    thus meant to explore different levels of trust for different
    sectors (government, nonprofits, and businesses). An example item is
    ‘Most of the time, we can trust people in nonprofits to do what is
    right’. Consistent with the original formulation, a 5-point Likert
    scale was used.

6.  Public sector feeling (Weißmüller 2016). This is a 1-item scale in
    which respondents can express the negativity or positivity of their
    feelings towards the public sector. The item was measured with a
    semantic difference 7-point scale, with ‘very negative’ and ‘very
    positive’ as the end labels for the scale. For the context of this
    study, numeric labels were placed on top of each scale point,
    ranging from ‘-3’ to ‘+3’.

7.  Political party identification. This had been measured with two
    items, the extent to which the respondents considered themselves to
    be conservative or liberal, respectively. The two items were
    formulated as ‘Do you consider yourself a conservative/liberal?’.
    Five answer options were possible: ‘definitely not’ (-2), ‘probably
    not’ (-1), ‘Might or might not’ (0), ‘probably yes’ (1) ‘definitely
    yes’ (2). The liberal item was reversed, and both items were
    combined as a measure of conservative political identification.
    Similar measures have been used in other studies.

8.  Social desirability (Strahan and Gerbasi 1972). A 10-item construct,
    similar to the social desirability construct from the first data
    collection, but with 10 different items. Items were measured on a
    7-point Likert scale with the values ranging from ‘strongly disagree
    (-3)’ to ‘strongly agree (3)’.

Finally, the questionnaire contained demographic questions on gender,
age, education, and employment.

### Results

Table 2 reports the values for the measured constructs in this data
collection.

``` r
summary(Sample.Demographics.emp.2)
```

    ##  Org_Experience      Org_Type       Org_Size     
    ##  Min.   : 1.000   Min.   :1.00   Min.   : 1.000  
    ##  1st Qu.: 4.000   1st Qu.:1.00   1st Qu.: 2.000  
    ##  Median : 6.000   Median :1.00   Median : 3.000  
    ##  Mean   : 7.152   Mean   :1.81   Mean   : 3.667  
    ##  3rd Qu.: 9.000   3rd Qu.:1.00   3rd Qu.: 5.000  
    ##  Max.   :42.000   Max.   :8.00   Max.   :10.000

``` r
nrow(Sample.Demographics.2)
```

    ## [1] 337

``` r
nrow(Sample.Demographics.emp.2)
```

    ## [1] 237

``` r
summary(Sample.Demographics.2)
```

    ##    Birthyear      Occupation      Education    
    ##  Min.   :1944   Min.   :1.000   Min.   :0.000  
    ##  1st Qu.:1976   1st Qu.:2.000   1st Qu.:2.000  
    ##  Median :1985   Median :2.000   Median :2.000  
    ##  Mean   :1982   Mean   :2.436   Mean   :2.371  
    ##  3rd Qu.:1989   3rd Qu.:3.000   3rd Qu.:3.000  
    ##  Max.   :1997   Max.   :6.000   Max.   :4.000

From the correlational analysis, several insights about convergent and
discriminant analysis can be developed. Relatedness of the three focal
scales with each other is substantially high, especially the attitudes
of the public sector and of the public servants (r = 0.72; p &lt; 0.05).
Given this high relatedness, both scales will be referred to in the
remainder of this text as the public service attitude scales. Moreover,
attitudes of politicians correlate positively with attitudes of the
public sector (0.39; p &lt; 0.05) and of public servants (0.51; p &lt;
0.05).

The public service attitude scales both relate similarly to public
service motivation and its four dimensions (values range between 0.25
and 0.34; p &lt; 0.05), and it also relates to the different measures of
government trust (correlation values range between 0.32 and 0.49; p &lt;
0.05). As a consequence, public service attitude scales show consistent
convergent validity with public service motivation and government trust.

In contrast, the attitudes of politicians only relate positively to the
government trust measures (even stronger than public service attitudes
scales do; correlation values range from 0.56 to 0.67; p &lt; 0.05), and
not with public service motivation (no significant correlations). This
distinct relatedness supports the discriminant validity of the scale on
the attitudes to politicians and suggests that the government has indeed
a stronger political connotation than the public sector and public
servants entities.

Moreover, when looking at trust in the different sectors (Bader 2016),
all the three attitude scales correlate positively with trust in
government, with the highest correlation for the attitudes to the
politicians (r = 0.65; p &lt; 0.05). This supports convergent validity.
Correlations are also positive, but they are less strong for trust in
the non-profit sector (values are around 0.30). However, the public
service attitude scales do not correlate or correlate only to a limited
extent to the trust in the businesses (r = 0.18; p &lt; 0.05),
supporting discriminant validity of these public service attitude
scales. Interestingly, for attitudes towards politicians, a (stronger)
significant correlation, as compared to the public service attitudes has
been observed for trust in businesses (r = 0.49; p &lt; 0.05).

The attitude towards the public sector and the public servants relate
negatively to political conservatism, which is also consistent with the
conservative political program in the U.S. to reduce public services and
limit the number of public servants. No correlation exists between the
attitudes towards politicians and conservatism.

Despite the fact that correlating items with the social desirability
construct in the first data collection were removed, the overall
attitude scales still correlated to a limited extent, but they
significantly correlated with the social desirability construct (values
range between 0.19 and 0.26; p &lt; 0.05). These are relatively small
effect sizes, but further critical reflection might be needed.

``` r
# summary(SCORES)
corrplot.mixed(M, lower.col = "black", number.cex = 1.0, upper = "pie", tl.col = "black", tl.pos = "l", p.mat = res1$p, sig.level = .05, insig = "blank")
```

![](README_files/figure-markdown_github/full%20correlation%20analysis%20-%20output-1.png)

``` r
#Download Correlation plot here: Willems, Jurgen (2020): Correlation plot - for attitudes towards the public sector, public servants, and politicians; and Public service motivation, Trust in government, Political orientation, Social desirability, etc. figshare. Figure. https://doi.org/10.6084/m9.figshare.12571232
```

[Download Correlation plot
here](https://doi.org/10.6084/m9.figshare.12571232) (Willems 2020d)

Step 4: Assessment of distinctiveness of the three focal scales.
----------------------------------------------------------------

``` r
# Item cross-loadings over the three scales
## 1. Samples selction with remaining items per entity

Sample.1a.PubSec <-subset(Sample.1a, select = c("A01_PubSec01" , "A04_PubSec02" , "A07_PubSec03" , "A10_PubSec04" , "A13_PubSec05" , "A17_PubSec06"  , "A20_PubSec07"  , "A23_PubSec08"  , "A26_PubSec09",  "A33_PubSec11", "A36_PubSec12" ,    "A42_PubSec14" ))
Sample.1a.PubServ <-subset(Sample.1a, select = c("A02_PubServ01",  "A11_PubServ04" ,  "A18_PubServ06" , "A21_PubServ07" ,  "A24_PubServ08",  "A27_PubServ09", "A30_PubServ10" , "A34_PubServ11" , "A37_PubServ12" ,  "A43_PubServ14", "A46_PubServ15"))
Sample.1a.pol <-subset(Sample.1a, select = c("A03_Pol01", "A09_Pol03",   "A19_Pol06" ,  "A31_Pol10" , "A35_Pol11" , "A41_Pol13"   ))
Sample.1b.PubSec <-subset(Sample.1b, select = c("B01_PubSec01", "B02_PubSec02", "B03_PubSec03", "B04_PubSec04", "B05_PubSec05", "B06_PubSec06", "B07_PubSec07", "B08_PubSec08", "B09_PubSec09",  "B11_PubSec11", "B12_PubSec12",  "B14_PubSec14"))
Sample.1b.PubServ <-subset(Sample.1b, select = c("B17_PubServ01",   "B20_PubServ04",  "B22_PubServ06", "B23_PubServ07", "B24_PubServ08", "B25_PubServ09", "B26_PubServ10", "B27_PubServ11", "B28_PubServ12", "B30_PubServ14", "B31_PubServ15"))
Sample.1b.pol <-subset(Sample.1b, select = c("B33_Pol01",  "B35_Pol03",   "B38_Pol06",    "B42_Pol10", "B43_Pol11", "B45_Pol13"))


## 1.1. Sample 1a: randomly mixed items: Exploratory and Confirmatory Factor analyses (FA)
## 1.1.1. Exploratory FA 
fac.data.1a <- cbind(Sample.1a.PubServ,Sample.1a.PubSec,Sample.1a.pol)
 fit.1ae <- factanal(fac.data.1a, 3, rotation="promax")
 print(fit.1ae, digits=2, cutoff=.3, sort=TRUE)
```

    ## 
    ## Call:
    ## factanal(x = fac.data.1a, factors = 3, rotation = "promax")
    ## 
    ## Uniquenesses:
    ## A02_PubServ01 A11_PubServ04 A18_PubServ06 A21_PubServ07 A24_PubServ08 
    ##          0.40          0.63          0.44          0.41          0.41 
    ## A27_PubServ09 A30_PubServ10 A34_PubServ11 A37_PubServ12 A43_PubServ14 
    ##          0.43          0.33          0.43          0.48          0.53 
    ## A46_PubServ15  A01_PubSec01  A04_PubSec02  A07_PubSec03  A10_PubSec04 
    ##          0.48          0.66          0.60          0.43          0.67 
    ##  A13_PubSec05  A17_PubSec06  A20_PubSec07  A23_PubSec08  A26_PubSec09 
    ##          0.48          0.41          0.59          0.43          0.58 
    ##  A33_PubSec11  A36_PubSec12  A42_PubSec14     A03_Pol01     A09_Pol03 
    ##          0.48          0.36          0.53          0.28          0.31 
    ##     A19_Pol06     A31_Pol10     A35_Pol11     A41_Pol13 
    ##          0.57          0.47          0.32          0.32 
    ## 
    ## Loadings:
    ##               Factor1 Factor2 Factor3
    ## A02_PubServ01  0.67                  
    ## A11_PubServ04  0.62                  
    ## A21_PubServ07  0.67                  
    ## A24_PubServ08  0.72                  
    ## A27_PubServ09  0.68                  
    ## A34_PubServ11  0.77                  
    ## A37_PubServ12  0.72                  
    ## A01_PubSec01   0.53                  
    ## A07_PubSec03   0.59                  
    ## A13_PubSec05   0.74                  
    ## A23_PubSec08   0.79                  
    ## A42_PubSec14   0.71                  
    ## A18_PubServ06          0.74          
    ## A30_PubServ10          0.65          
    ## A43_PubServ14          0.61          
    ## A46_PubServ15          0.67          
    ## A10_PubSec04           0.55          
    ## A17_PubSec06           0.65          
    ## A33_PubSec11           0.76          
    ## A36_PubSec12           0.76          
    ## A19_Pol06      0.47    0.65          
    ## A31_Pol10              0.67   -0.30  
    ## A03_Pol01                      0.80  
    ## A09_Pol03                      0.80  
    ## A35_Pol11                      0.77  
    ## A41_Pol13                      0.81  
    ## A04_PubSec02   0.41                  
    ## A20_PubSec07  -0.33    0.43    0.33  
    ## A26_PubSec09  -0.38    0.37    0.37  
    ## 
    ##                Factor1 Factor2 Factor3
    ## SS loadings       6.59    4.97    3.22
    ## Proportion Var    0.23    0.17    0.11
    ## Cumulative Var    0.23    0.40    0.51
    ## 
    ## Factor Correlations:
    ##         Factor1 Factor2 Factor3
    ## Factor1    1.00   -0.22   -0.56
    ## Factor2   -0.22    1.00    0.35
    ## Factor3   -0.56    0.35    1.00
    ## 
    ## Test of the hypothesis that 3 factors are sufficient.
    ## The chi square statistic is 1108.63 on 322 degrees of freedom.
    ## The p-value is 5.49e-87

``` r
## 1.1.2. Confirmatory FA  - 
## 1.1.2.1 Confirmatory FA  - 3 dimensions
 model.3dim <- '  PubSec =~
A01_PubSec01 + A04_PubSec02 + A07_PubSec03 + A10_PubSec04 + A13_PubSec05 + A17_PubSec06 + A20_PubSec07 + A23_PubSec08 + A26_PubSec09 + A33_PubSec11 +A36_PubSec12 + A42_PubSec14
PubServ =~
A02_PubServ01 +  A11_PubServ04 + A18_PubServ06 + A21_PubServ07 +  A24_PubServ08+  A27_PubServ09 + A30_PubServ10 + A34_PubServ11 + A37_PubServ12 +  A43_PubServ14+ A46_PubServ15
Pol =~
A03_Pol01  + A09_Pol03 +  A19_Pol06 +  A31_Pol10 + A35_Pol11 + A41_Pol13   '
fit.3dim.1a <- cfa(model.3dim, data = fac.data.1a)
summary(fit.3dim.1a, header=TRUE, standardized=TRUE, fit.measures=TRUE, estimates = FALSE, modindices = FALSE, ci=FALSE, rsquare=FALSE)
```

    ## lavaan 0.6-4 ended normally after 45 iterations
    ## 
    ##   Optimization method                           NLMINB
    ##   Number of free parameters                         61
    ## 
    ##   Number of observations                           325
    ## 
    ##   Estimator                                         ML
    ##   Model Fit Test Statistic                    2091.597
    ##   Degrees of freedom                               374
    ##   P-value (Chi-square)                           0.000
    ## 
    ## Model test baseline model:
    ## 
    ##   Minimum Function Test Statistic             6318.629
    ##   Degrees of freedom                               406
    ##   P-value                                        0.000
    ## 
    ## User model versus baseline model:
    ## 
    ##   Comparative Fit Index (CFI)                    0.710
    ##   Tucker-Lewis Index (TLI)                       0.685
    ## 
    ## Loglikelihood and Information Criteria:
    ## 
    ##   Loglikelihood user model (H0)             -15614.364
    ##   Loglikelihood unrestricted model (H1)     -14568.565
    ## 
    ##   Number of free parameters                         61
    ##   Akaike (AIC)                               31350.728
    ##   Bayesian (BIC)                             31581.541
    ##   Sample-size adjusted Bayesian (BIC)        31388.054
    ## 
    ## Root Mean Square Error of Approximation:
    ## 
    ##   RMSEA                                          0.119
    ##   90 Percent Confidence Interval          0.114  0.124
    ##   P-value RMSEA <= 0.05                          0.000
    ## 
    ## Standardized Root Mean Square Residual:
    ## 
    ##   SRMR                                           0.104

``` r
## 1.1.2.2 Confirmatory FA  - 2 dimensions
 model.2dim <- '  
PubSec =~
A01_PubSec01 + A04_PubSec02 + A07_PubSec03 + A10_PubSec04 + A13_PubSec05 + A17_PubSec06 + A20_PubSec07 + A23_PubSec08 + A26_PubSec09 + A33_PubSec11 +A36_PubSec12 +    A42_PubSec14
+
A02_PubServ01 +  A11_PubServ04 + A18_PubServ06 + A21_PubServ07 +  A24_PubServ08+  A27_PubServ09 + A30_PubServ10 + A34_PubServ11 + A37_PubServ12 +  A43_PubServ14+ A46_PubServ15
Pol =~
A03_Pol01  + A09_Pol03 +  A19_Pol06 +  A31_Pol10 + A35_Pol11 + A41_Pol13   '
fit.2dim.1a <- cfa(model.2dim, data = fac.data.1a)
summary(fit.2dim.1a, header=TRUE, standardized=TRUE, fit.measures=TRUE,estimates = FALSE,modindices = FALSE, ci=FALSE, rsquare=FALSE)
```

    ## lavaan 0.6-4 ended normally after 42 iterations
    ## 
    ##   Optimization method                           NLMINB
    ##   Number of free parameters                         59
    ## 
    ##   Number of observations                           325
    ## 
    ##   Estimator                                         ML
    ##   Model Fit Test Statistic                    2133.653
    ##   Degrees of freedom                               376
    ##   P-value (Chi-square)                           0.000
    ## 
    ## Model test baseline model:
    ## 
    ##   Minimum Function Test Statistic             6318.629
    ##   Degrees of freedom                               406
    ##   P-value                                        0.000
    ## 
    ## User model versus baseline model:
    ## 
    ##   Comparative Fit Index (CFI)                    0.703
    ##   Tucker-Lewis Index (TLI)                       0.679
    ## 
    ## Loglikelihood and Information Criteria:
    ## 
    ##   Loglikelihood user model (H0)             -15635.392
    ##   Loglikelihood unrestricted model (H1)     -14568.565
    ## 
    ##   Number of free parameters                         59
    ##   Akaike (AIC)                               31388.783
    ##   Bayesian (BIC)                             31612.029
    ##   Sample-size adjusted Bayesian (BIC)        31424.886
    ## 
    ## Root Mean Square Error of Approximation:
    ## 
    ##   RMSEA                                          0.120
    ##   90 Percent Confidence Interval          0.115  0.125
    ##   P-value RMSEA <= 0.05                          0.000
    ## 
    ## Standardized Root Mean Square Residual:
    ## 
    ##   SRMR                                           0.103

``` r
## 1.1.2.3 Comparing models 

anova(fit.3dim.1a , fit.2dim.1a)
```

    ## Chi Square Difference Test
    ## 
    ##              Df   AIC   BIC  Chisq Chisq diff Df diff Pr(>Chisq)    
    ## fit.3dim.1a 374 31351 31582 2091.6                                  
    ## fit.2dim.1a 376 31389 31612 2133.7     42.056       2  7.375e-10 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

``` r
## 1.2. Sample 1b: items per entity: Exploratory and Confirmatory Factor analyses
## 1.2.1.  Exploratory FA 
fac.data.1b <- cbind(Sample.1b.PubServ,Sample.1b.PubSec,Sample.1b.pol)
 fit.1be <- factanal(fac.data.1b, 3, rotation="promax")
 print(fit.1be, digits=2, cutoff=.3, sort=TRUE)
```

    ## 
    ## Call:
    ## factanal(x = fac.data.1b, factors = 3, rotation = "promax")
    ## 
    ## Uniquenesses:
    ## B17_PubServ01 B20_PubServ04 B22_PubServ06 B23_PubServ07 B24_PubServ08 
    ##          0.24          0.63          0.58          0.25          0.38 
    ## B25_PubServ09 B26_PubServ10 B27_PubServ11 B28_PubServ12 B30_PubServ14 
    ##          0.49          0.41          0.39          0.34          0.65 
    ## B31_PubServ15  B01_PubSec01  B02_PubSec02  B03_PubSec03  B04_PubSec04 
    ##          0.52          0.52          0.55          0.40          0.67 
    ##  B05_PubSec05  B06_PubSec06  B07_PubSec07  B08_PubSec08  B09_PubSec09 
    ##          0.42          0.44          0.55          0.33          0.49 
    ##  B11_PubSec11  B12_PubSec12  B14_PubSec14     B33_Pol01     B35_Pol03 
    ##          0.65          0.39          0.54          0.21          0.20 
    ##     B38_Pol06     B42_Pol10     B43_Pol11     B45_Pol13 
    ##          0.86          0.59          0.28          0.38 
    ## 
    ## Loadings:
    ##               Factor1 Factor2 Factor3
    ## B01_PubSec01   0.68                  
    ## B02_PubSec02   0.66                  
    ## B03_PubSec03   0.69                  
    ## B04_PubSec04  -0.54                  
    ## B05_PubSec05   0.87                  
    ## B06_PubSec06  -0.62                  
    ## B07_PubSec07  -0.68                  
    ## B08_PubSec08   0.87                  
    ## B09_PubSec09  -0.62                  
    ## B11_PubSec11  -0.62                  
    ## B12_PubSec12  -0.77                  
    ## B14_PubSec14   0.74                  
    ## B17_PubServ01          0.89          
    ## B22_PubServ06         -0.56          
    ## B23_PubServ07          0.91          
    ## B24_PubServ08          0.74          
    ## B25_PubServ09          0.59          
    ## B26_PubServ10         -0.66          
    ## B27_PubServ11          0.76          
    ## B28_PubServ12          0.92          
    ## B30_PubServ14         -0.61          
    ## B31_PubServ15         -0.64          
    ## B33_Pol01                      0.88  
    ## B35_Pol03                      0.89  
    ## B42_Pol10                     -0.60  
    ## B43_Pol11                      0.82  
    ## B45_Pol13                      0.80  
    ## B20_PubServ04          0.42          
    ## B38_Pol06                     -0.39  
    ## 
    ##                Factor1 Factor2 Factor3
    ## SS loadings       6.14    5.84    3.66
    ## Proportion Var    0.21    0.20    0.13
    ## Cumulative Var    0.21    0.41    0.54
    ## 
    ## Factor Correlations:
    ##         Factor1 Factor2 Factor3
    ## Factor1    1.00    0.35   -0.61
    ## Factor2    0.35    1.00   -0.29
    ## Factor3   -0.61   -0.29    1.00
    ## 
    ## Test of the hypothesis that 3 factors are sufficient.
    ## The chi square statistic is 1155.62 on 322 degrees of freedom.
    ## The p-value is 2.58e-94

``` r
## 1.2.2.  Confirmatory FA 
 model.3dim <- '   PubSec =~
B01_PubSec01 + B02_PubSec02 + B03_PubSec03 + B04_PubSec04+ B05_PubSec05+ B06_PubSec06+ B07_PubSec07+ B08_PubSec08 + B09_PubSec09 +  B11_PubSec11+ B12_PubSec12+  B14_PubSec14
PubServ =~
B17_PubServ01+   B20_PubServ04+  B22_PubServ06+ B23_PubServ07+ B24_PubServ08+ B25_PubServ09+ B26_PubServ10+ B27_PubServ11+ B28_PubServ12+ B30_PubServ14+ B31_PubServ15
Pol =~
B33_Pol01+  B35_Pol03+   B38_Pol06+    B42_Pol10+ B43_Pol11+ B45_Pol13    '

fit.3dim.1b <- cfa(model.3dim, data = fac.data.1b)
summary(fit.3dim.1b, header=TRUE, standardized=TRUE, fit.measures=TRUE,estimates = FALSE, modindices = FALSE, ci=FALSE, rsquare=FALSE)
```

    ## lavaan 0.6-4 ended normally after 41 iterations
    ## 
    ##   Optimization method                           NLMINB
    ##   Number of free parameters                         61
    ## 
    ##   Number of observations                           320
    ## 
    ##   Estimator                                         ML
    ##   Model Fit Test Statistic                    1444.951
    ##   Degrees of freedom                               374
    ##   P-value (Chi-square)                           0.000
    ## 
    ## Model test baseline model:
    ## 
    ##   Minimum Function Test Statistic             6512.920
    ##   Degrees of freedom                               406
    ##   P-value                                        0.000
    ## 
    ## User model versus baseline model:
    ## 
    ##   Comparative Fit Index (CFI)                    0.825
    ##   Tucker-Lewis Index (TLI)                       0.810
    ## 
    ## Loglikelihood and Information Criteria:
    ## 
    ##   Loglikelihood user model (H0)             -14509.036
    ##   Loglikelihood unrestricted model (H1)     -13786.561
    ## 
    ##   Number of free parameters                         61
    ##   Akaike (AIC)                               29140.072
    ##   Bayesian (BIC)                             29369.940
    ##   Sample-size adjusted Bayesian (BIC)        29176.459
    ## 
    ## Root Mean Square Error of Approximation:
    ## 
    ##   RMSEA                                          0.095
    ##   90 Percent Confidence Interval          0.089  0.100
    ##   P-value RMSEA <= 0.05                          0.000
    ## 
    ## Standardized Root Mean Square Residual:
    ## 
    ##   SRMR                                           0.077

``` r
## 1.3. Sample 3: items per entity (reduced scales): Exploratory and Confirmatory Factor analyses
## 1.3.1. Exploratory FA 
fac.data.2 <- cbind(Sample.2.PubServ,Sample.2.PubSec,Sample.2.pol)
 fit.2e <- factanal(fac.data.2, 3, rotation="promax")
 print(fit.2e, digits=2, cutoff=.2, sort=TRUE)
```

    ## 
    ## Call:
    ## factanal(x = fac.data.2, factors = 3, rotation = "promax")
    ## 
    ## Uniquenesses:
    ## PubServ01 PubServ04 PubServ06 PubServ07 PubServ08 PubServ09 PubServ10 
    ##      0.21      0.71      0.50      0.25      0.32      0.44      0.43 
    ## PubServ11 PubServ12 PubServ14 PubServ15  PubSec01  PubSec02  PubSec03 
    ##      0.38      0.26      0.62      0.66      0.62      0.62      0.50 
    ##  PubSec04  PubSec05  PubSec06  PubSec07  PubSec08  PubSec09  PubSec11 
    ##      0.55      0.48      0.40      0.51      0.41      0.49      0.51 
    ##  PubSec12  PubSec14     Pol01     Pol03     Pol06     Pol10     Pol11 
    ##      0.35      0.54      0.23      0.17      0.85      0.58      0.23 
    ##     Pol13 
    ##      0.38 
    ## 
    ## Loadings:
    ##           Factor1 Factor2 Factor3
    ## PubSec01  -0.63                  
    ## PubSec02  -0.59                  
    ## PubSec03  -0.61                  
    ## PubSec04   0.68                  
    ## PubSec05  -0.74                  
    ## PubSec06   0.78                  
    ## PubSec07   0.79            0.21  
    ## PubSec08  -0.78                  
    ## PubSec09   0.79                  
    ## PubSec11   0.81    0.26          
    ## PubSec12   0.86                  
    ## PubSec14  -0.66                  
    ## PubServ01          0.87          
    ## PubServ07          0.84          
    ## PubServ08          0.80          
    ## PubServ11          0.68          
    ## PubServ12          0.93          
    ## Pol01                      0.87  
    ## Pol03                      0.93  
    ## Pol10                     -0.58  
    ## Pol11                      0.86  
    ## Pol13                      0.80  
    ## PubServ04 -0.45                  
    ## PubServ06  0.37   -0.35          
    ## PubServ09 -0.35    0.47          
    ## PubServ10  0.42   -0.39          
    ## PubServ14  0.33   -0.31          
    ## PubServ15  0.38                  
    ## Pol06      0.25    0.22   -0.34  
    ## 
    ##                Factor1 Factor2 Factor3
    ## SS loadings       7.45    4.26    3.74
    ## Proportion Var    0.26    0.15    0.13
    ## Cumulative Var    0.26    0.40    0.53
    ## 
    ## Factor Correlations:
    ##         Factor1 Factor2 Factor3
    ## Factor1    1.00   -0.49    0.70
    ## Factor2   -0.49    1.00   -0.45
    ## Factor3    0.70   -0.45    1.00
    ## 
    ## Test of the hypothesis that 3 factors are sufficient.
    ## The chi square statistic is 1360.67 on 322 degrees of freedom.
    ## The p-value is 1.63e-127

``` r
## 1.3.2. Confirmatory FA 
## 1.3.2.1  Wilh three dimensions specified
model.3dim <- '   
PubSec =~ PubSec01 + PubSec02 + PubSec03 + PubSec04 + PubSec05+ PubSec06 + PubSec07 + PubSec08 + PubSec09 +  PubSec11 + PubSec12 +  PubSec14 
PubServ =~ PubServ01+   PubServ04+ PubServ06+ PubServ07+ PubServ08+ PubServ09+ PubServ10+ PubServ11+ PubServ12+ PubServ14+ PubServ15
Pol =~ Pol01+  Pol03+   Pol06+    Pol10+ Pol11+ Pol13    '
fit.3dim.2 <- cfa(model.3dim, data = fac.data.2)
summary(fit.3dim.2, header=TRUE, standardized=TRUE, fit.measures=TRUE,estimates = TRUE,modindices = FALSE, ci=TRUE, rsquare=TRUE)
```

    ## lavaan 0.6-4 ended normally after 46 iterations
    ## 
    ##   Optimization method                           NLMINB
    ##   Number of free parameters                         61
    ## 
    ##   Number of observations                           337
    ## 
    ##   Estimator                                         ML
    ##   Model Fit Test Statistic                    1678.123
    ##   Degrees of freedom                               374
    ##   P-value (Chi-square)                           0.000
    ## 
    ## Model test baseline model:
    ## 
    ##   Minimum Function Test Statistic             7311.524
    ##   Degrees of freedom                               406
    ##   P-value                                        0.000
    ## 
    ## User model versus baseline model:
    ## 
    ##   Comparative Fit Index (CFI)                    0.811
    ##   Tucker-Lewis Index (TLI)                       0.795
    ## 
    ## Loglikelihood and Information Criteria:
    ## 
    ##   Loglikelihood user model (H0)             -15119.029
    ##   Loglikelihood unrestricted model (H1)     -14279.967
    ## 
    ##   Number of free parameters                         61
    ##   Akaike (AIC)                               30360.058
    ##   Bayesian (BIC)                             30593.083
    ##   Sample-size adjusted Bayesian (BIC)        30399.582
    ## 
    ## Root Mean Square Error of Approximation:
    ## 
    ##   RMSEA                                          0.102
    ##   90 Percent Confidence Interval          0.097  0.107
    ##   P-value RMSEA <= 0.05                          0.000
    ## 
    ## Standardized Root Mean Square Residual:
    ## 
    ##   SRMR                                           0.078
    ## 
    ## Parameter Estimates:
    ## 
    ##   Information                                 Expected
    ##   Information saturated (h1) model          Structured
    ##   Standard Errors                             Standard
    ## 
    ## Latent Variables:
    ##                    Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper
    ##   PubSec =~                                                             
    ##     PubSec01          1.000                               1.000    1.000
    ##     PubSec02          0.909    0.089   10.221    0.000    0.734    1.083
    ##     PubSec03          1.047    0.091   11.497    0.000    0.869    1.226
    ##     PubSec04         -0.886    0.084  -10.593    0.000   -1.050   -0.722
    ##     PubSec05          1.147    0.096   11.891    0.000    0.958    1.336
    ##     PubSec06         -0.956    0.079  -12.029    0.000   -1.111   -0.800
    ##     PubSec07         -0.816    0.075  -10.840    0.000   -0.964   -0.669
    ##     PubSec08          1.214    0.098   12.379    0.000    1.022    1.406
    ##     PubSec09         -0.777    0.070  -11.087    0.000   -0.914   -0.640
    ##     PubSec11         -0.905    0.085  -10.645    0.000   -1.072   -0.738
    ##     PubSec12         -1.037    0.084  -12.297    0.000   -1.202   -0.871
    ##     PubSec14          1.127    0.100   11.219    0.000    0.930    1.323
    ##   PubServ =~                                                            
    ##     PubServ01         1.000                               1.000    1.000
    ##     PubServ04         0.561    0.061    9.124    0.000    0.440    0.681
    ##     PubServ06        -0.736    0.047  -15.812    0.000   -0.827   -0.644
    ##     PubServ07         1.033    0.051   20.380    0.000    0.934    1.133
    ##     PubServ08         0.965    0.053   18.164    0.000    0.861    1.069
    ##     PubServ09         0.897    0.054   16.564    0.000    0.790    1.003
    ##     PubServ10        -0.811    0.048  -17.044    0.000   -0.904   -0.718
    ##     PubServ11         1.043    0.059   17.551    0.000    0.927    1.160
    ##     PubServ12         1.020    0.054   18.839    0.000    0.914    1.127
    ##     PubServ14        -0.664    0.051  -13.041    0.000   -0.764   -0.564
    ##     PubServ15        -0.616    0.054  -11.396    0.000   -0.722   -0.510
    ##   Pol =~                                                                
    ##     Pol01             1.000                               1.000    1.000
    ##     Pol03             1.011    0.042   24.295    0.000    0.930    1.093
    ##     Pol06            -0.412    0.071   -5.827    0.000   -0.550   -0.273
    ##     Pol10            -0.795    0.060  -13.268    0.000   -0.912   -0.678
    ##     Pol11             0.948    0.041   22.869    0.000    0.867    1.029
    ##     Pol13             0.862    0.046   18.666    0.000    0.772    0.953
    ##    Std.lv  Std.all
    ##                   
    ##     1.098    0.644
    ##     0.998    0.624
    ##     1.150    0.718
    ##    -0.972   -0.650
    ##     1.259    0.748
    ##    -1.049   -0.759
    ##    -0.896   -0.668
    ##     1.333    0.787
    ##    -0.853   -0.687
    ##    -0.993   -0.654
    ##    -1.138   -0.780
    ##     1.237    0.697
    ##                   
    ##     1.365    0.858
    ##     0.766    0.474
    ##    -1.004   -0.726
    ##     1.411    0.848
    ##     1.317    0.793
    ##     1.224    0.748
    ##    -1.107   -0.762
    ##     1.424    0.777
    ##     1.393    0.811
    ##    -0.907   -0.633
    ##    -0.842   -0.570
    ##                   
    ##     1.184    0.885
    ##     1.198    0.907
    ##    -0.488   -0.316
    ##    -0.942   -0.634
    ##     1.123    0.880
    ##     1.022    0.791
    ## 
    ## Covariances:
    ##                    Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper
    ##   PubSec ~~                                                             
    ##     PubServ           1.118    0.134    8.360    0.000    0.856    1.381
    ##     Pol               0.523    0.089    5.857    0.000    0.348    0.698
    ##   PubServ ~~                                                            
    ##     Pol               0.886    0.112    7.935    0.000    0.667    1.104
    ##    Std.lv  Std.all
    ##                   
    ##     0.746    0.746
    ##     0.402    0.402
    ##                   
    ##     0.548    0.548
    ## 
    ## Variances:
    ##                    Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper
    ##    .PubSec01          1.697    0.138   12.293    0.000    1.426    1.967
    ##    .PubSec02          1.564    0.126   12.365    0.000    1.316    1.812
    ##    .PubSec03          1.244    0.104   11.952    0.000    1.040    1.448
    ##    .PubSec04          1.290    0.105   12.272    0.000    1.084    1.496
    ##    .PubSec05          1.247    0.106   11.748    0.000    1.039    1.455
    ##    .PubSec06          0.810    0.069   11.663    0.000    0.674    0.946
    ##    .PubSec07          0.995    0.082   12.199    0.000    0.835    1.155
    ##    .PubSec08          1.091    0.096   11.401    0.000    0.903    1.278
    ##    .PubSec09          0.816    0.067   12.117    0.000    0.684    0.948
    ##    .PubSec11          1.320    0.108   12.257    0.000    1.109    1.531
    ##    .PubSec12          0.831    0.072   11.469    0.000    0.689    0.973
    ##    .PubSec14          1.623    0.134   12.068    0.000    1.360    1.887
    ##    .PubServ01         0.668    0.062   10.850    0.000    0.547    0.788
    ##    .PubServ04         2.025    0.159   12.761    0.000    1.714    2.336
    ##    .PubServ06         0.907    0.075   12.136    0.000    0.760    1.053
    ##    .PubServ07         0.776    0.070   11.025    0.000    0.638    0.914
    ##    .PubServ08         1.023    0.088   11.690    0.000    0.852    1.195
    ##    .PubServ09         1.177    0.098   12.014    0.000    0.985    1.370
    ##    .PubServ10         0.884    0.074   11.927    0.000    0.738    1.029
    ##    .PubServ11         1.336    0.113   11.826    0.000    1.114    1.557
    ##    .PubServ12         1.012    0.088   11.520    0.000    0.840    1.184
    ##    .PubServ14         1.231    0.099   12.475    0.000    1.038    1.425
    ##    .PubServ15         1.472    0.117   12.616    0.000    1.243    1.701
    ##    .Pol01             0.388    0.040    9.586    0.000    0.308    0.467
    ##    .Pol03             0.311    0.036    8.652    0.000    0.240    0.381
    ##    .Pol06             2.136    0.166   12.881    0.000    1.811    2.461
    ##    .Pol10             1.319    0.107   12.374    0.000    1.110    1.528
    ##    .Pol11             0.368    0.038    9.775    0.000    0.294    0.442
    ##    .Pol13             0.626    0.055   11.457    0.000    0.519    0.733
    ##     PubSec            1.205    0.187    6.455    0.000    0.839    1.571
    ##     PubServ           1.864    0.191    9.753    0.000    1.490    2.239
    ##     Pol               1.403    0.137   10.211    0.000    1.134    1.672
    ##    Std.lv  Std.all
    ##     1.697    0.585
    ##     1.564    0.611
    ##     1.244    0.485
    ##     1.290    0.577
    ##     1.247    0.440
    ##     0.810    0.424
    ##     0.995    0.553
    ##     1.091    0.381
    ##     0.816    0.528
    ##     1.320    0.572
    ##     0.831    0.391
    ##     1.623    0.515
    ##     0.668    0.264
    ##     2.025    0.775
    ##     0.907    0.473
    ##     0.776    0.281
    ##     1.023    0.371
    ##     1.177    0.440
    ##     0.884    0.419
    ##     1.336    0.397
    ##     1.012    0.343
    ##     1.231    0.600
    ##     1.472    0.675
    ##     0.388    0.216
    ##     0.311    0.178
    ##     2.136    0.900
    ##     1.319    0.598
    ##     0.368    0.226
    ##     0.626    0.375
    ##     1.000    1.000
    ##     1.000    1.000
    ##     1.000    1.000
    ## 
    ## R-Square:
    ##                    Estimate
    ##     PubSec01          0.415
    ##     PubSec02          0.389
    ##     PubSec03          0.515
    ##     PubSec04          0.423
    ##     PubSec05          0.560
    ##     PubSec06          0.576
    ##     PubSec07          0.447
    ##     PubSec08          0.619
    ##     PubSec09          0.472
    ##     PubSec11          0.428
    ##     PubSec12          0.609
    ##     PubSec14          0.485
    ##     PubServ01         0.736
    ##     PubServ04         0.225
    ##     PubServ06         0.527
    ##     PubServ07         0.719
    ##     PubServ08         0.629
    ##     PubServ09         0.560
    ##     PubServ10         0.581
    ##     PubServ11         0.603
    ##     PubServ12         0.657
    ##     PubServ14         0.400
    ##     PubServ15         0.325
    ##     Pol01             0.784
    ##     Pol03             0.822
    ##     Pol06             0.100
    ##     Pol10             0.402
    ##     Pol11             0.774
    ##     Pol13             0.625

``` r
mi <- modindices(fit.3dim.2)
mi <- mi[mi$op == "=~",]
mi[with(mi, order(-mi)), ]
```

    ##         lhs op       rhs     mi    epc sepc.lv sepc.all sepc.nox
    ## 66   PubSec =~ PubServ04 21.396  0.557   0.611    0.378    0.378
    ## 102     Pol =~  PubSec03 15.934  0.246   0.291    0.182    0.182
    ## 106     Pol =~  PubSec07 14.769  0.209   0.248    0.185    0.185
    ## 65   PubSec =~ PubServ01 10.592 -0.249  -0.273   -0.172   -0.172
    ## 70   PubSec =~ PubServ09 10.590  0.310   0.340    0.208    0.208
    ## 68   PubSec =~ PubServ07 10.274 -0.262  -0.287   -0.173   -0.173
    ## 73   PubSec =~ PubServ12 10.081 -0.288  -0.316   -0.184   -0.184
    ## 71   PubSec =~ PubServ10  9.267 -0.252  -0.277   -0.191   -0.191
    ## 108     Pol =~  PubSec09  9.172  0.150   0.177    0.143    0.143
    ## 119     Pol =~ PubServ11  7.197 -0.191  -0.226   -0.123   -0.123
    ## 105     Pol =~  PubSec06  7.113 -0.134  -0.159   -0.115   -0.115
    ## 101     Pol =~  PubSec02  6.928  0.178   0.211    0.132    0.132
    ## 75   PubSec =~ PubServ15  6.816 -0.270  -0.296   -0.201   -0.201
    ## 97  PubServ =~     Pol10  6.691 -0.154  -0.210   -0.141   -0.141
    ## 113     Pol =~ PubServ04  5.624 -0.199  -0.235   -0.146   -0.146
    ## 104     Pol =~  PubSec05  5.521 -0.146  -0.173   -0.103   -0.103
    ## 116     Pol =~ PubServ08  5.172  0.143   0.169    0.102    0.102
    ## 107     Pol =~  PubSec08  4.477 -0.125  -0.148   -0.088   -0.088
    ## 79   PubSec =~     Pol10  4.443 -0.142  -0.155   -0.105   -0.105
    ## 95  PubServ =~     Pol03  4.028 -0.070  -0.096   -0.072   -0.072
    ## 69   PubSec =~ PubServ08  3.910 -0.179  -0.196   -0.118   -0.118
    ## 112     Pol =~ PubServ01  3.614  0.100   0.119    0.075    0.075
    ## 67   PubSec =~ PubServ06  3.266 -0.150  -0.165   -0.119   -0.119
    ## 74   PubSec =~ PubServ14  2.912 -0.162  -0.178   -0.124   -0.124
    ## 84  PubServ =~  PubSec03  2.441  0.123   0.168    0.105    0.105
    ## 87  PubServ =~  PubSec06  2.372 -0.099  -0.135   -0.098   -0.098
    ## 78   PubSec =~     Pol06  2.360 -0.128  -0.141   -0.092   -0.092
    ## 86  PubServ =~  PubSec05  2.310 -0.121  -0.165   -0.098   -0.098
    ## 118     Pol =~ PubServ10  2.174  0.085   0.101    0.069    0.069
    ## 77   PubSec =~     Pol03  2.167 -0.058  -0.063   -0.048   -0.048
    ## 103     Pol =~  PubSec04  2.107 -0.090  -0.106   -0.071   -0.071
    ## 72   PubSec =~ PubServ11  2.032  0.146   0.160    0.087    0.087
    ## 122     Pol =~ PubServ15  1.788 -0.096  -0.114   -0.077   -0.077
    ## 88  PubServ =~  PubSec07  1.735  0.091   0.125    0.093    0.093
    ## 109     Pol =~  PubSec11  1.611 -0.079  -0.094   -0.062   -0.062
    ## 91  PubServ =~  PubSec11  1.576  0.100   0.136    0.090    0.090
    ## 85  PubServ =~  PubSec04  1.492 -0.096  -0.131   -0.088   -0.088
    ## 120     Pol =~ PubServ12  1.447 -0.076  -0.090   -0.052   -0.052
    ## 110     Pol =~  PubSec12  1.208 -0.057  -0.067   -0.046   -0.046
    ## 98  PubServ =~     Pol11  1.139  0.038   0.052    0.041    0.041
    ## 115     Pol =~ PubServ07  1.098  0.059   0.070    0.042    0.042
    ## 111     Pol =~  PubSec14  1.030 -0.071  -0.084   -0.047   -0.047
    ## 92  PubServ =~  PubSec12  0.904 -0.063  -0.086   -0.059   -0.059
    ## 76   PubSec =~     Pol01  0.881  0.039   0.043    0.032    0.032
    ## 90  PubServ =~  PubSec09  0.791  0.056   0.077    0.062    0.062
    ## 99  PubServ =~     Pol13  0.743 -0.037  -0.050   -0.039   -0.039
    ## 117     Pol =~ PubServ09  0.671 -0.054  -0.064   -0.039   -0.039
    ## 82  PubServ =~  PubSec01  0.499 -0.064  -0.087   -0.051   -0.051
    ## 96  PubServ =~     Pol06  0.447 -0.049  -0.067   -0.044   -0.044
    ## 114     Pol =~ PubServ06  0.322 -0.033  -0.039   -0.028   -0.028
    ## 81   PubSec =~     Pol13  0.306 -0.027  -0.029   -0.023   -0.023
    ## 100     Pol =~  PubSec01  0.236 -0.034  -0.041   -0.024   -0.024
    ## 89  PubServ =~  PubSec08  0.228 -0.036  -0.049   -0.029   -0.029
    ## 93  PubServ =~  PubSec14  0.169  0.037   0.050    0.028    0.028
    ## 94  PubServ =~     Pol01  0.106  0.012   0.016    0.012    0.012
    ## 80   PubSec =~     Pol11  0.092 -0.012  -0.013   -0.010   -0.010
    ## 121     Pol =~ PubServ14  0.051  0.015   0.018    0.012    0.012
    ## 83  PubServ =~  PubSec02  0.003  0.005   0.007    0.004    0.004

``` r
## 1.3.2.2  With two dimensions specified - Sector and Servants attitudes combined
model.2dim <- '   
PubSecServ =~ PubSec01 + PubSec02 + PubSec03 + PubSec04 + PubSec05+ PubSec06 + PubSec07 + PubSec08 + PubSec09 +  PubSec11 + PubSec12 +  PubSec14 
+ PubServ01+   PubServ04+ PubServ06+ PubServ07+ PubServ08+ PubServ09+ PubServ10+ PubServ11+ PubServ12+ PubServ14+ PubServ15
Pol =~ Pol01+  Pol03+   Pol06+    Pol10+ Pol11+ Pol13    '
fit.2dim.2 <- cfa(model.2dim, data = fac.data.2)
summary(fit.2dim.2, header=TRUE, standardized=TRUE, fit.measures=TRUE,estimates = FALSE,modindices = FALSE, ci=FALSE, rsquare=FALSE)
```

    ## lavaan 0.6-4 ended normally after 40 iterations
    ## 
    ##   Optimization method                           NLMINB
    ##   Number of free parameters                         59
    ## 
    ##   Number of observations                           337
    ## 
    ##   Estimator                                         ML
    ##   Model Fit Test Statistic                    2216.479
    ##   Degrees of freedom                               376
    ##   P-value (Chi-square)                           0.000
    ## 
    ## Model test baseline model:
    ## 
    ##   Minimum Function Test Statistic             7311.524
    ##   Degrees of freedom                               406
    ##   P-value                                        0.000
    ## 
    ## User model versus baseline model:
    ## 
    ##   Comparative Fit Index (CFI)                    0.733
    ##   Tucker-Lewis Index (TLI)                       0.712
    ## 
    ## Loglikelihood and Information Criteria:
    ## 
    ##   Loglikelihood user model (H0)             -15388.207
    ##   Loglikelihood unrestricted model (H1)     -14279.967
    ## 
    ##   Number of free parameters                         59
    ##   Akaike (AIC)                               30894.414
    ##   Bayesian (BIC)                             31119.799
    ##   Sample-size adjusted Bayesian (BIC)        30932.643
    ## 
    ## Root Mean Square Error of Approximation:
    ## 
    ##   RMSEA                                          0.121
    ##   90 Percent Confidence Interval          0.116  0.125
    ##   P-value RMSEA <= 0.05                          0.000
    ## 
    ## Standardized Root Mean Square Residual:
    ## 
    ##   SRMR                                           0.090

``` r
## 1.3.2.3  All itens in 1 dimension specified
model.1dim <- '   
PubSecServPol =~ PubSec01 + PubSec02 + PubSec03 + PubSec04 + PubSec05+ PubSec06 + PubSec07 + PubSec08 + PubSec09 +  PubSec11 + PubSec12 +  PubSec14 
+ PubServ01+   PubServ04+ PubServ06+ PubServ07+ PubServ08+ PubServ09+ PubServ10+ PubServ11+ PubServ12+ PubServ14+ PubServ15
+ Pol01+  Pol03+   Pol06+    Pol10+ Pol11+ Pol13    '
fit.1dim.2 <- cfa(model.1dim, data = fac.data.2)
summary(fit.1dim.2, header=TRUE, standardized=TRUE, fit.measures=TRUE,estimates = FALSE,modindices = FALSE, ci=FALSE, rsquare=FALSE)
```

    ## lavaan 0.6-4 ended normally after 33 iterations
    ## 
    ##   Optimization method                           NLMINB
    ##   Number of free parameters                         58
    ## 
    ##   Number of observations                           337
    ## 
    ##   Estimator                                         ML
    ##   Model Fit Test Statistic                    3118.011
    ##   Degrees of freedom                               377
    ##   P-value (Chi-square)                           0.000
    ## 
    ## Model test baseline model:
    ## 
    ##   Minimum Function Test Statistic             7311.524
    ##   Degrees of freedom                               406
    ##   P-value                                        0.000
    ## 
    ## User model versus baseline model:
    ## 
    ##   Comparative Fit Index (CFI)                    0.603
    ##   Tucker-Lewis Index (TLI)                       0.573
    ## 
    ## Loglikelihood and Information Criteria:
    ## 
    ##   Loglikelihood user model (H0)             -15838.973
    ##   Loglikelihood unrestricted model (H1)     -14279.967
    ## 
    ##   Number of free parameters                         58
    ##   Akaike (AIC)                               31793.946
    ##   Bayesian (BIC)                             32015.511
    ##   Sample-size adjusted Bayesian (BIC)        31831.527
    ## 
    ## Root Mean Square Error of Approximation:
    ## 
    ##   RMSEA                                          0.147
    ##   90 Percent Confidence Interval          0.142  0.152
    ##   P-value RMSEA <= 0.05                          0.000
    ## 
    ## Standardized Root Mean Square Residual:
    ## 
    ##   SRMR                                           0.113

``` r
## 1.3.3  Comparing models

anova(fit.2dim.2 , fit.3dim.2 )
```

    ## Chi Square Difference Test
    ## 
    ##             Df   AIC   BIC  Chisq Chisq diff Df diff Pr(>Chisq)    
    ## fit.3dim.2 374 30360 30593 1678.1                                  
    ## fit.2dim.2 376 30894 31120 2216.5     538.36       2  < 2.2e-16 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

``` r
anova(fit.1dim.2 , fit.3dim.2 )
```

    ## Chi Square Difference Test
    ## 
    ##             Df   AIC   BIC  Chisq Chisq diff Df diff Pr(>Chisq)    
    ## fit.3dim.2 374 30360 30593 1678.1                                  
    ## fit.1dim.2 377 31794 32016 3118.0     1439.9       3  < 2.2e-16 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Despite the fact that all the three scales focused on distinct entities
in the government and public service field, it is valuable to explore
the extent to which all three scales are distinct from each other from a
measurement perspective. Therefore, scale validation tests that are
commonly used to get an insight into the discriminant validity of
construct dimensions can inform us about the distinctiveness in
measurement of the three scales. Therefore, exploratory factor analysis
had been done on Samples 1 and 2, and confirmatory factor analysis had
been done on Sample 3. However, it has to be noted that the scales in
this study are not seen as dimensions of an overall multi-dimensional
construct. Therefore, these tests rather explore theoretical and/or
mentally associated relatedness of these entities, and the
interchangeability of these scales.

From the correlational analysis above, distinctiveness of the attitudes
towards politicians from the attitudes towards public services can
preliminary be confirmed due to different relatedness with the citizen’s
trust in the government and the motivation to engage in public service.
However, attitudes towards the public sector and towards the public
servants seem substantially less distinct (at least from the perspective
of the measurement scale). This is also supported by the outputs of both
the exploratory (Samples 1 and 2) and the confirmatory factor analyses
(Sample 3) based on the remaining items. For example, when conducting an
exploratory factor analysis (Maximum Likelihood, 3 factors extracted,
promax rotation, loading cut-off = 0.3) for the stream of completely
randomized item order (Sample 1), one factor clearly groups a set of
politician attitude items, while the other two factors group
combinations of the attitude towards the public sector and towards
public servants (one factor with positively formulated items, and one
with negatively formulated items). Hence, when asked in a combined
manner, measures of attitudes towards the public sector and towards
public servants are not very distinct. The exploratory factor analysis
in the second sample, i.e. when items are grouped as per entity, shows
more clearly the factor loading that is consistent with the entities.

``` r
print(fit.1ae, digits=2, cutoff=.3, sort=TRUE)
```

    ## 
    ## Call:
    ## factanal(x = fac.data.1a, factors = 3, rotation = "promax")
    ## 
    ## Uniquenesses:
    ## A02_PubServ01 A11_PubServ04 A18_PubServ06 A21_PubServ07 A24_PubServ08 
    ##          0.40          0.63          0.44          0.41          0.41 
    ## A27_PubServ09 A30_PubServ10 A34_PubServ11 A37_PubServ12 A43_PubServ14 
    ##          0.43          0.33          0.43          0.48          0.53 
    ## A46_PubServ15  A01_PubSec01  A04_PubSec02  A07_PubSec03  A10_PubSec04 
    ##          0.48          0.66          0.60          0.43          0.67 
    ##  A13_PubSec05  A17_PubSec06  A20_PubSec07  A23_PubSec08  A26_PubSec09 
    ##          0.48          0.41          0.59          0.43          0.58 
    ##  A33_PubSec11  A36_PubSec12  A42_PubSec14     A03_Pol01     A09_Pol03 
    ##          0.48          0.36          0.53          0.28          0.31 
    ##     A19_Pol06     A31_Pol10     A35_Pol11     A41_Pol13 
    ##          0.57          0.47          0.32          0.32 
    ## 
    ## Loadings:
    ##               Factor1 Factor2 Factor3
    ## A02_PubServ01  0.67                  
    ## A11_PubServ04  0.62                  
    ## A21_PubServ07  0.67                  
    ## A24_PubServ08  0.72                  
    ## A27_PubServ09  0.68                  
    ## A34_PubServ11  0.77                  
    ## A37_PubServ12  0.72                  
    ## A01_PubSec01   0.53                  
    ## A07_PubSec03   0.59                  
    ## A13_PubSec05   0.74                  
    ## A23_PubSec08   0.79                  
    ## A42_PubSec14   0.71                  
    ## A18_PubServ06          0.74          
    ## A30_PubServ10          0.65          
    ## A43_PubServ14          0.61          
    ## A46_PubServ15          0.67          
    ## A10_PubSec04           0.55          
    ## A17_PubSec06           0.65          
    ## A33_PubSec11           0.76          
    ## A36_PubSec12           0.76          
    ## A19_Pol06      0.47    0.65          
    ## A31_Pol10              0.67   -0.30  
    ## A03_Pol01                      0.80  
    ## A09_Pol03                      0.80  
    ## A35_Pol11                      0.77  
    ## A41_Pol13                      0.81  
    ## A04_PubSec02   0.41                  
    ## A20_PubSec07  -0.33    0.43    0.33  
    ## A26_PubSec09  -0.38    0.37    0.37  
    ## 
    ##                Factor1 Factor2 Factor3
    ## SS loadings       6.59    4.97    3.22
    ## Proportion Var    0.23    0.17    0.11
    ## Cumulative Var    0.23    0.40    0.51
    ## 
    ## Factor Correlations:
    ##         Factor1 Factor2 Factor3
    ## Factor1    1.00   -0.22   -0.56
    ## Factor2   -0.22    1.00    0.35
    ## Factor3   -0.56    0.35    1.00
    ## 
    ## Test of the hypothesis that 3 factors are sufficient.
    ## The chi square statistic is 1108.63 on 322 degrees of freedom.
    ## The p-value is 5.49e-87

``` r
print(fit.1be, digits=2, cutoff=.3, sort=TRUE)
```

    ## 
    ## Call:
    ## factanal(x = fac.data.1b, factors = 3, rotation = "promax")
    ## 
    ## Uniquenesses:
    ## B17_PubServ01 B20_PubServ04 B22_PubServ06 B23_PubServ07 B24_PubServ08 
    ##          0.24          0.63          0.58          0.25          0.38 
    ## B25_PubServ09 B26_PubServ10 B27_PubServ11 B28_PubServ12 B30_PubServ14 
    ##          0.49          0.41          0.39          0.34          0.65 
    ## B31_PubServ15  B01_PubSec01  B02_PubSec02  B03_PubSec03  B04_PubSec04 
    ##          0.52          0.52          0.55          0.40          0.67 
    ##  B05_PubSec05  B06_PubSec06  B07_PubSec07  B08_PubSec08  B09_PubSec09 
    ##          0.42          0.44          0.55          0.33          0.49 
    ##  B11_PubSec11  B12_PubSec12  B14_PubSec14     B33_Pol01     B35_Pol03 
    ##          0.65          0.39          0.54          0.21          0.20 
    ##     B38_Pol06     B42_Pol10     B43_Pol11     B45_Pol13 
    ##          0.86          0.59          0.28          0.38 
    ## 
    ## Loadings:
    ##               Factor1 Factor2 Factor3
    ## B01_PubSec01   0.68                  
    ## B02_PubSec02   0.66                  
    ## B03_PubSec03   0.69                  
    ## B04_PubSec04  -0.54                  
    ## B05_PubSec05   0.87                  
    ## B06_PubSec06  -0.62                  
    ## B07_PubSec07  -0.68                  
    ## B08_PubSec08   0.87                  
    ## B09_PubSec09  -0.62                  
    ## B11_PubSec11  -0.62                  
    ## B12_PubSec12  -0.77                  
    ## B14_PubSec14   0.74                  
    ## B17_PubServ01          0.89          
    ## B22_PubServ06         -0.56          
    ## B23_PubServ07          0.91          
    ## B24_PubServ08          0.74          
    ## B25_PubServ09          0.59          
    ## B26_PubServ10         -0.66          
    ## B27_PubServ11          0.76          
    ## B28_PubServ12          0.92          
    ## B30_PubServ14         -0.61          
    ## B31_PubServ15         -0.64          
    ## B33_Pol01                      0.88  
    ## B35_Pol03                      0.89  
    ## B42_Pol10                     -0.60  
    ## B43_Pol11                      0.82  
    ## B45_Pol13                      0.80  
    ## B20_PubServ04          0.42          
    ## B38_Pol06                     -0.39  
    ## 
    ##                Factor1 Factor2 Factor3
    ## SS loadings       6.14    5.84    3.66
    ## Proportion Var    0.21    0.20    0.13
    ## Cumulative Var    0.21    0.41    0.54
    ## 
    ## Factor Correlations:
    ##         Factor1 Factor2 Factor3
    ## Factor1    1.00    0.35   -0.61
    ## Factor2    0.35    1.00   -0.29
    ## Factor3   -0.61   -0.29    1.00
    ## 
    ## Test of the hypothesis that 3 factors are sufficient.
    ## The chi square statistic is 1155.62 on 322 degrees of freedom.
    ## The p-value is 2.58e-94

When performing confirmatory factor analysis for the third sample, with
three factors (one per entity) and no cross-loading items specified,
model fit is not sufficient to conclude clear discriminant validity (CFI
= 0.811; TLI = 0.795; RMSEA = 0.102; BIC = 30593.083). However, model
fit is still better as compared to the two-factor model with the items
of attitudes towards public sector and public servants in one factor
(Chi-Square difference = 538.36; df = 2; p &lt; 0.001; BIC = 31119.799),
and compared to a single-factor model (Chi-Square difference = 1439.9;
df = 3; p &lt; 0.001; BIC = 32015.511). The modification indices in the
three-dimensional models indeed suggest allowing cross-loadings, mainly
between the scales of the attitudes towards public sector and towards
public servants. Hence, these factor analyses show that scale
distinctiveness is low, or non-existent for the attitudes towards public
sector and towards public servants. This has likely to do with the fact
that servants are a major part of the sector, and scale items are,
therefore, driven by the same mental framework, or latent cognition of
public services as a whole. However, from a practical point, this means
that both scales are to a large extent interchangeable (e.g. when the
research question does not particularly focus on one of the specific
entities, they might be combined as a single scale, or used
interchangeably). Table 1 reports the factor loadings of the
confirmatory factor analysis of Sample 3.

``` r
summary(fit.3dim.2, header=TRUE, standardized=TRUE, fit.measures=TRUE,estimates = TRUE,modindices = FALSE, ci=TRUE, rsquare=TRUE)
```

    ## lavaan 0.6-4 ended normally after 46 iterations
    ## 
    ##   Optimization method                           NLMINB
    ##   Number of free parameters                         61
    ## 
    ##   Number of observations                           337
    ## 
    ##   Estimator                                         ML
    ##   Model Fit Test Statistic                    1678.123
    ##   Degrees of freedom                               374
    ##   P-value (Chi-square)                           0.000
    ## 
    ## Model test baseline model:
    ## 
    ##   Minimum Function Test Statistic             7311.524
    ##   Degrees of freedom                               406
    ##   P-value                                        0.000
    ## 
    ## User model versus baseline model:
    ## 
    ##   Comparative Fit Index (CFI)                    0.811
    ##   Tucker-Lewis Index (TLI)                       0.795
    ## 
    ## Loglikelihood and Information Criteria:
    ## 
    ##   Loglikelihood user model (H0)             -15119.029
    ##   Loglikelihood unrestricted model (H1)     -14279.967
    ## 
    ##   Number of free parameters                         61
    ##   Akaike (AIC)                               30360.058
    ##   Bayesian (BIC)                             30593.083
    ##   Sample-size adjusted Bayesian (BIC)        30399.582
    ## 
    ## Root Mean Square Error of Approximation:
    ## 
    ##   RMSEA                                          0.102
    ##   90 Percent Confidence Interval          0.097  0.107
    ##   P-value RMSEA <= 0.05                          0.000
    ## 
    ## Standardized Root Mean Square Residual:
    ## 
    ##   SRMR                                           0.078
    ## 
    ## Parameter Estimates:
    ## 
    ##   Information                                 Expected
    ##   Information saturated (h1) model          Structured
    ##   Standard Errors                             Standard
    ## 
    ## Latent Variables:
    ##                    Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper
    ##   PubSec =~                                                             
    ##     PubSec01          1.000                               1.000    1.000
    ##     PubSec02          0.909    0.089   10.221    0.000    0.734    1.083
    ##     PubSec03          1.047    0.091   11.497    0.000    0.869    1.226
    ##     PubSec04         -0.886    0.084  -10.593    0.000   -1.050   -0.722
    ##     PubSec05          1.147    0.096   11.891    0.000    0.958    1.336
    ##     PubSec06         -0.956    0.079  -12.029    0.000   -1.111   -0.800
    ##     PubSec07         -0.816    0.075  -10.840    0.000   -0.964   -0.669
    ##     PubSec08          1.214    0.098   12.379    0.000    1.022    1.406
    ##     PubSec09         -0.777    0.070  -11.087    0.000   -0.914   -0.640
    ##     PubSec11         -0.905    0.085  -10.645    0.000   -1.072   -0.738
    ##     PubSec12         -1.037    0.084  -12.297    0.000   -1.202   -0.871
    ##     PubSec14          1.127    0.100   11.219    0.000    0.930    1.323
    ##   PubServ =~                                                            
    ##     PubServ01         1.000                               1.000    1.000
    ##     PubServ04         0.561    0.061    9.124    0.000    0.440    0.681
    ##     PubServ06        -0.736    0.047  -15.812    0.000   -0.827   -0.644
    ##     PubServ07         1.033    0.051   20.380    0.000    0.934    1.133
    ##     PubServ08         0.965    0.053   18.164    0.000    0.861    1.069
    ##     PubServ09         0.897    0.054   16.564    0.000    0.790    1.003
    ##     PubServ10        -0.811    0.048  -17.044    0.000   -0.904   -0.718
    ##     PubServ11         1.043    0.059   17.551    0.000    0.927    1.160
    ##     PubServ12         1.020    0.054   18.839    0.000    0.914    1.127
    ##     PubServ14        -0.664    0.051  -13.041    0.000   -0.764   -0.564
    ##     PubServ15        -0.616    0.054  -11.396    0.000   -0.722   -0.510
    ##   Pol =~                                                                
    ##     Pol01             1.000                               1.000    1.000
    ##     Pol03             1.011    0.042   24.295    0.000    0.930    1.093
    ##     Pol06            -0.412    0.071   -5.827    0.000   -0.550   -0.273
    ##     Pol10            -0.795    0.060  -13.268    0.000   -0.912   -0.678
    ##     Pol11             0.948    0.041   22.869    0.000    0.867    1.029
    ##     Pol13             0.862    0.046   18.666    0.000    0.772    0.953
    ##    Std.lv  Std.all
    ##                   
    ##     1.098    0.644
    ##     0.998    0.624
    ##     1.150    0.718
    ##    -0.972   -0.650
    ##     1.259    0.748
    ##    -1.049   -0.759
    ##    -0.896   -0.668
    ##     1.333    0.787
    ##    -0.853   -0.687
    ##    -0.993   -0.654
    ##    -1.138   -0.780
    ##     1.237    0.697
    ##                   
    ##     1.365    0.858
    ##     0.766    0.474
    ##    -1.004   -0.726
    ##     1.411    0.848
    ##     1.317    0.793
    ##     1.224    0.748
    ##    -1.107   -0.762
    ##     1.424    0.777
    ##     1.393    0.811
    ##    -0.907   -0.633
    ##    -0.842   -0.570
    ##                   
    ##     1.184    0.885
    ##     1.198    0.907
    ##    -0.488   -0.316
    ##    -0.942   -0.634
    ##     1.123    0.880
    ##     1.022    0.791
    ## 
    ## Covariances:
    ##                    Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper
    ##   PubSec ~~                                                             
    ##     PubServ           1.118    0.134    8.360    0.000    0.856    1.381
    ##     Pol               0.523    0.089    5.857    0.000    0.348    0.698
    ##   PubServ ~~                                                            
    ##     Pol               0.886    0.112    7.935    0.000    0.667    1.104
    ##    Std.lv  Std.all
    ##                   
    ##     0.746    0.746
    ##     0.402    0.402
    ##                   
    ##     0.548    0.548
    ## 
    ## Variances:
    ##                    Estimate  Std.Err  z-value  P(>|z|) ci.lower ci.upper
    ##    .PubSec01          1.697    0.138   12.293    0.000    1.426    1.967
    ##    .PubSec02          1.564    0.126   12.365    0.000    1.316    1.812
    ##    .PubSec03          1.244    0.104   11.952    0.000    1.040    1.448
    ##    .PubSec04          1.290    0.105   12.272    0.000    1.084    1.496
    ##    .PubSec05          1.247    0.106   11.748    0.000    1.039    1.455
    ##    .PubSec06          0.810    0.069   11.663    0.000    0.674    0.946
    ##    .PubSec07          0.995    0.082   12.199    0.000    0.835    1.155
    ##    .PubSec08          1.091    0.096   11.401    0.000    0.903    1.278
    ##    .PubSec09          0.816    0.067   12.117    0.000    0.684    0.948
    ##    .PubSec11          1.320    0.108   12.257    0.000    1.109    1.531
    ##    .PubSec12          0.831    0.072   11.469    0.000    0.689    0.973
    ##    .PubSec14          1.623    0.134   12.068    0.000    1.360    1.887
    ##    .PubServ01         0.668    0.062   10.850    0.000    0.547    0.788
    ##    .PubServ04         2.025    0.159   12.761    0.000    1.714    2.336
    ##    .PubServ06         0.907    0.075   12.136    0.000    0.760    1.053
    ##    .PubServ07         0.776    0.070   11.025    0.000    0.638    0.914
    ##    .PubServ08         1.023    0.088   11.690    0.000    0.852    1.195
    ##    .PubServ09         1.177    0.098   12.014    0.000    0.985    1.370
    ##    .PubServ10         0.884    0.074   11.927    0.000    0.738    1.029
    ##    .PubServ11         1.336    0.113   11.826    0.000    1.114    1.557
    ##    .PubServ12         1.012    0.088   11.520    0.000    0.840    1.184
    ##    .PubServ14         1.231    0.099   12.475    0.000    1.038    1.425
    ##    .PubServ15         1.472    0.117   12.616    0.000    1.243    1.701
    ##    .Pol01             0.388    0.040    9.586    0.000    0.308    0.467
    ##    .Pol03             0.311    0.036    8.652    0.000    0.240    0.381
    ##    .Pol06             2.136    0.166   12.881    0.000    1.811    2.461
    ##    .Pol10             1.319    0.107   12.374    0.000    1.110    1.528
    ##    .Pol11             0.368    0.038    9.775    0.000    0.294    0.442
    ##    .Pol13             0.626    0.055   11.457    0.000    0.519    0.733
    ##     PubSec            1.205    0.187    6.455    0.000    0.839    1.571
    ##     PubServ           1.864    0.191    9.753    0.000    1.490    2.239
    ##     Pol               1.403    0.137   10.211    0.000    1.134    1.672
    ##    Std.lv  Std.all
    ##     1.697    0.585
    ##     1.564    0.611
    ##     1.244    0.485
    ##     1.290    0.577
    ##     1.247    0.440
    ##     0.810    0.424
    ##     0.995    0.553
    ##     1.091    0.381
    ##     0.816    0.528
    ##     1.320    0.572
    ##     0.831    0.391
    ##     1.623    0.515
    ##     0.668    0.264
    ##     2.025    0.775
    ##     0.907    0.473
    ##     0.776    0.281
    ##     1.023    0.371
    ##     1.177    0.440
    ##     0.884    0.419
    ##     1.336    0.397
    ##     1.012    0.343
    ##     1.231    0.600
    ##     1.472    0.675
    ##     0.388    0.216
    ##     0.311    0.178
    ##     2.136    0.900
    ##     1.319    0.598
    ##     0.368    0.226
    ##     0.626    0.375
    ##     1.000    1.000
    ##     1.000    1.000
    ##     1.000    1.000
    ## 
    ## R-Square:
    ##                    Estimate
    ##     PubSec01          0.415
    ##     PubSec02          0.389
    ##     PubSec03          0.515
    ##     PubSec04          0.423
    ##     PubSec05          0.560
    ##     PubSec06          0.576
    ##     PubSec07          0.447
    ##     PubSec08          0.619
    ##     PubSec09          0.472
    ##     PubSec11          0.428
    ##     PubSec12          0.609
    ##     PubSec14          0.485
    ##     PubServ01         0.736
    ##     PubServ04         0.225
    ##     PubServ06         0.527
    ##     PubServ07         0.719
    ##     PubServ08         0.629
    ##     PubServ09         0.560
    ##     PubServ10         0.581
    ##     PubServ11         0.603
    ##     PubServ12         0.657
    ##     PubServ14         0.400
    ##     PubServ15         0.325
    ##     Pol01             0.784
    ##     Pol03             0.822
    ##     Pol06             0.100
    ##     Pol10             0.402
    ##     Pol11             0.774
    ##     Pol13             0.625

Step 5: Shortened scales for practical use
------------------------------------------

``` r
#Public Sector
ChooseBest(it.Sample.1b.PubSec, n=4)
```

    ## [1] "B08_PubSec08" "B12_PubSec12" "B03_PubSec03" "B06_PubSec06"

``` r
Sample.2.PubSec.short <-subset(Sample.2, select = c("PubSec08", "PubSec03", "PubSec12", "PubSec05")) 
Scale.Sample.2.PubSec.short <- Scale(data = Sample.2.PubSec.short, reverse = c("PubSec12"))
prep.Sample.2.PubSec.short <- PreProc(Scale.Sample.2.PubSec.short)
it.Sample.2.PubSec.short <- ItemAnalysis(prep.Sample.2.PubSec.short, method="spearman", fm="gls", nfactors=1, rcut= 0.4, score_type="z", exclude=c()) 
it.Sample.2.PubSec.short
```

    ## 
    ## Reliability Analysis of prep.Sample.2.PubSec.short ScaleData object. 
    ## 
    ## A spearman correlation matrix of 4 items was calculated and submitted to Reliability analysis.
    ##       
    ## The overall Cronbach's Alpha was 0.84 .
    ## A gls factor analysis was conducted. Items were regressed to
    ##       a single factor. Their loadings are the following:
    ##  PubSec03  PubSec12  PubSec05  PubSec08 
    ## 0.7025479 0.7090218 0.7965602 0.8265470

``` r
Att.Pub.Sector.short <- -(( Sample.2.PubSec$PubSec03 + Sample.2.PubSec$PubSec05 + Sample.2.PubSec$PubSec08   -  Sample.2.PubSec$PubSec12 )/4)
```

``` r
#Public Servants
ChooseBest(it.Sample.1b.PubServ, n=4)
```

    ## [1] "B17_PubServ01" "B23_PubServ07" "B27_PubServ11" "B28_PubServ12"

``` r
Sample.2.PubServ.short <-subset(Sample.2, select = c("PubServ01", "PubServ07", "PubServ11", "PubServ12"))
Scale.Sample.2.PubServ.short <- Scale(data = Sample.2.PubServ.short, reverse = c())
prep.Sample.2.PubServ.short <- PreProc(Scale.Sample.2.PubServ.short)
it.Sample.2.PubServ.short <- ItemAnalysis(prep.Sample.2.PubServ.short, method="spearman", fm="gls", nfactors=1, rcut= 0.4, score_type="z", exclude=c()) 
it.Sample.2.PubServ.short
```

    ## 
    ## Reliability Analysis of prep.Sample.2.PubServ.short ScaleData object. 
    ## 
    ## A spearman correlation matrix of 4 items was calculated and submitted to Reliability analysis.
    ##       
    ## The overall Cronbach's Alpha was 0.9 .
    ## A gls factor analysis was conducted. Items were regressed to
    ##       a single factor. Their loadings are the following:
    ## PubServ11 PubServ12 PubServ07 PubServ01 
    ## 0.7446048 0.8582005 0.8715172 0.8793570

``` r
Att.Pub.Servants.short <- -(Sample.2.PubServ$PubServ01 + Sample.2.PubServ$PubServ07 + Sample.2.PubServ$PubServ11  + Sample.2.PubServ$PubServ12)/4
```

``` r
#Politicians
ChooseBest(it.Sample.1b.pol, n=4)
```

    ## [1] "B33_Pol01" "B35_Pol03" "B43_Pol11" "B45_Pol13"

``` r
Sample.2.pol.short <-subset(Sample.2, select = c("Pol01", "Pol03", "Pol11", "Pol13"))
Scale.Sample.2.pol.short <- Scale(data = Sample.2.pol.short, reverse = c())
prep.Sample.2.pol.short <- PreProc(Scale.Sample.2.pol.short)
it.Sample.2.pol.short <- ItemAnalysis(prep.Sample.2.pol.short, method="spearman", fm="gls", nfactors=1, rcut= 0.4, score_type="z", exclude=c()) 
it.Sample.2.pol.short
```

    ## 
    ## Reliability Analysis of prep.Sample.2.pol.short ScaleData object. 
    ## 
    ## A spearman correlation matrix of 4 items was calculated and submitted to Reliability analysis.
    ##       
    ## The overall Cronbach's Alpha was 0.92 .
    ## A gls factor analysis was conducted. Items were regressed to
    ##       a single factor. Their loadings are the following:
    ##     Pol13     Pol11     Pol01     Pol03 
    ## 0.8129644 0.8512066 0.8728081 0.9095051

``` r
Att.Politicians.short <- -(Sample.2.pol$Pol01 + Sample.2.pol$Pol03 + Sample.2.pol$Pol11+Sample.2.pol$Pol13)/4
```

As the aim of this study is to develop three scales that can easily be
integrated in other studies, this step focuses on selecting items for
more concise scales that have enough internal consistency. Based on
Sample 2, four items per scale were selected based on a generalized
least squares factor analysis with items regressed on a single factor
(Giallousis 2015). The four best loading items per scale were selected.
In addition, Cronbach’s alpha for these items based on sample 3 are
reported as a cross-sample validation check. The selected items, loading
and Cronbach’s alpha values are reported in Table 4. These reduced
scales can thus be used as an overall measures of attitude towards the
three focal entities. Moreover, a correlational analysis, similar to
Step 3, but with shortened scales results in a very similar finding,
which can be consulted in the online appendix. Moreover, it has to be
noted that most of the remaining items were formulated in a negative
manner. It is thus recommended to reverse the loadings or the item
scores when using the scale in other research designs, as positive
scores are then expressing positive attitudes.

Discussion and further research
===============================

The aim of this study was to develop three related attitude scales and
test their relatedness with a set of core constructs from the literature
regarding public management. These scales can, in turn, be used in the
growing body of literature that deals with how the attitudes of citizens
towards the public field explain their behavior. Despite the fact that a
clear conceptual distinction is possible to be made between the focal
entities that are researched, attitudes and measures of the attitudes
can be overlapping and mutually influencing (Van de Walle 2008).
Consequently, the attitudes towards the public sector in general and
public servants as a part of this sector are highly related, and the
scales are not clearly distinct. Potentially, social processes of
self-selection and socialization of public servants within the sector
result in related perceptions among citizens, which, in turn, explains
the related attitudes towards these two entities (Becker and Connor
2005; De Cooman et al. 2011).

Convergent validity could be derived from a relatedness analysis with
other public management constructs. The relatedness of trust in
government with all the three attitude scales, but especially with the
attitudes towards politicians, suggest that the term “government” is
broader, and it groups both the political aspect as well as the public
service aspect. In contrast, the distinct relatedness with public
service motivation, which is more focused on the managerial and
operational public service aspect (Perry and Wise 1990) shows that
attitudes towards politician are unrelated to concrete motivations.

Moreover, motivation towards public service is not only related or
restricted to the public service or the field of government. For
example, public service motivation is positively correlated with trust
in non-profit organizations (correlations range between 0.28 and 0.35),
and less with trust in businesses and government (most correlations are
not significant). High public service motivation can thus be fulfilled
through participation and involvement in various types of socially
oriented organizations, from which some public-sector organizations are
an option (Vandenabeele 2007).

Political orientation, i.e. being rather conservative versus being
liberal, also relates differently to the attitudes towards the public
sector and the attitudes towards public servants on the one hand, and to
the attitudes towards politician on the other hand. Inherent to the
conservative political ideology in the U.S., a rather negative attitude
exists towards the public sector and its employees (Bean and Papadakis
1998).

A critical note has to be made about the observation that (almost) all
constructs in the second wave of the data collection still correlate to
some extent with a measure of social desirability. Potentially, the
common question type of the Likert scale items might be at the origin of
this level of relatedness. Therefore, further exploration and
validations in the field of public management scales could not only
consider the item content, but also alternative scale formats, such as
the Guttman scale and the semantic differential scale. Such elaboration
can continue the clarification of whether the measured relatedness of
constructs is the result of substantial relationships or of the tools
that we use (George and Pandey 2017).

From a theoretical perspective, the newly developed scales can assist in
the advancement of a broader research agenda on the behavior of citizens
in relation to public services and the government in general. The
attitudes of citizens are the result of culture, wide-spread beliefs,
and accumulated personal experiences (James 2011). Attitudes can, thus,
be included in further studies to explain the additional variance in
individual differences for citizen-bureaucracy interactions, in
particular, in the choice pertaining to engaging in citizen
participation initiatives and/or public service co-production (Clark and
Jang 2013; Yang and Callahan 2007).

Attitudes can also change due to new experiences and information(Eagly
and Chaiken 1993). Hence, attitudes are also an important focal concept
which can be explained as a dependent variable, for example in the
context of public-sector performance evaluations. Initial attitudes can
potentially be an important explaining factor, especially in the field
of public-performance assessments and citizen-satisfaction evaluations
(Van Ryzin et al. 2004; Morgeson 2013). In turn, the impact on attitudes
of recurrent changes in satisfaction as a result of experienced
performance which deviates from initial expectation could also be
tested. Similarly, in the context of citizen participation and
co-production, the experience and the obtained information through this
participation might eventually influence the attitudes of citizens
(Halachmi and Holzer 2010).

Limitations
===========

In addition to the validation tests in this study, such as item quality,
scale reliability, and construct validity (convergent and discriminant
validity), several further validation steps could be performed. Despite
the fact that citizen attitudes can change over time, further steps
could focus on test-retest validity. In addition, further steps are also
needed to test the predictive validity, for example, based on the
hypothesized effects in the previous section that attitudes might
explain the decision to engage in the participation of citizens and
co-production initiatives; or attitudes might affect how citizens form
an opinion on particular public-service experiences, and with that their
satisfaction evaluations.

The open-source nature of this project, with the data being fully
available, contributes to this philosophy of further testing and
scrutinizing these attitude scales in public management research.

Conclusion
==========

Three related scales on public sector, public servants, and politician
attitudes were developed and validated. Attitude scales for the public
sector and public servant respectively show low measurement
distinctiveness. In contrast, attitudes towards politicians are more
distinct also with respect to relatedness with other government-focused
constructs.

References
==========

Albrecht, Simon, and Anthony Travaglione. 2003. “Trust in Public-Sector
Senior Management.” *The International Journal of Human Resource
Management* 14 (1): 76–92. <https://doi.org/10.1080/09585190210158529>.

Alwin, Duane F. 1997. “Feeling Thermometers Versus 7-Point Scales: Which
Are Better?” *Sociological Methods & Research* 25 (3): 318–40.

Bader, Michael D. M. 2016. *Diversity in the D.c. Area: Findings from
the 2016 D.c. Area Survey*. 14th ed. Vol. 14. 14th Ser. CLALS working
paper series.
<http://www.american.edu/spa/metro-policy/upload/DC-Area-Study_Bader.pdf>.

Bean, Clive, and Elim Papadakis. 1998. “A Comparison of Mass Attitudes
Towards the Welfare State in Different Institutional Regimes,
1985-1990.” *International Journal of Public Opinion Research* 10 (3):
211–36. <https://doi.org/10.1093/ijpor/10.3.211>.

Becker, Boris W., and Patrick E. Connor. 2005. “Self-Selection or
Socialization of Public- and Private-Sector Managers? A Cross-Cultural
Values Analysis.” *Journal of Business Research* 58 (1): 111–13.

Beirão, Gabriela, and J.A. Sarsfield Cabral. 2007. “Understanding
Attitudes Towards Public Transport and Private Car: A Qualitative
Study.” *Transport Policy* 14 (6): 478–89.
<https://doi.org/10.1016/j.tranpol.2007.04.009>.

Billiet, Jaak B., and Eldad Davidov. 2008. “Testing the Stability of an
Acquiescence Style Factor Behind Two Interrelated Substantive Variables
in a Panel Design.” *Sociological Methods & Research* 36 (4): 542–62.

Bollen, Kenneth, and Lennox Richard. 1991. “Conventional Wisdom on
Measurement: A Structural Equation Perspective.” *Psychological
Bulletin* 110 (2): 305–14.

Borsboom, Denny, Gideon J. Mellenbergh, and Jaap van Heerden. 2003.
“Theoretical Status of Latent Variables.” *Psychological Review* 110
(2): 203–19.

Choi, Yujin. 2017. “Work Values, Job Characteristics, and Career Choice
Decisions: Evidence from Longitudinal Data.” *The American Review of
Public Administration* 47 (7): 779–96.
<https://doi.org/10.1177/0275074016653469>.

Christensen, Tom, and Per Lægreid. 2003. *Trust in Government – the
Significance of Attitudes Towards Democracy, the Public Sector and
Public Sector Reforms*. 43284th Ser. Stein Rokkan Centre for Social
Studies. <http://hdl.handle.net/1956/1400>.

Clark, Jeffrey L., Benjamin Y. AND Brudney, and Sung-Gheel Jang. 2013.
“Coproduction of Government Services and the New Information Technology:
Investigating the Distributional Biases.” *Public Administration Review*
73 (5): 687–701.

De Cooman, Rein, Sara De Gieter, Roland Pepermans, and Marc Jegers.
2011. “A Cross-Sector Comparison of Motivation-Related Concepts in
for-Profit and Not-for-Profit Service Organizations.” *Nonprofit and
Voluntary Sector Quarterly* 40 (2): 296–317.

DeVellis, Robert F. 2003. *Scale Development: Theory and Applications*.
2nd ed. London: Sage Publications.

Eagly, Alice. H., and Shelly Chaiken. 1993. *The Psychology of
Attitudes*. Orlando, FL: Harcourt Brace Jovanovich College Publishers.

———. 2007. “The Advantages of an Inclusive Definition of Attitude.”
*Social Cognition* 25 (5): 582–602.

Ek, Kristina. 2005. “Public and Private Attitudes Towards ‘Green’
Electricity: The Case of Swedish Wind Power.” *Energy Policy* 33 (13):
1677–89. <https://doi.org/10.1016/j.enpol.2004.02.005>.

Fischer, Donald G., and Carol Fick. 1993. “Measuring Social
Desirability: Short Forms of the Marlowe-Crowne Social Desirability
Scale.” *Educational and Psychological Measurement* 53 (2): 417–24.
<https://doi.org/10.1177/0013164493053002011>.

Foddy, William. 1993. *Constructing Questions for Interviews and
Questionnaires: Theory and Practice in Social Research*. Cambridge:
Cambridge University Press; Cambridge University Press.

Gawronski, Bertram. 2007. “Attitudes Can Be Measured! But What Is an
Attitude?” *Social Cognition* 25 (5): 573–81.

George, Bert, and Sanjay K. Pandey. 2017. “We Know the Yin—but Where Is
the Yang? Toward a Balanced Approach on Common Source Bias in Public
Administration Scholarship.” *Review of Public Personnel Administration*
37 (2): 245–70. <https://doi.org/10.1177/0734371X17698189>.

Giallousis, Nikolaos. 2015. *Scale: Likert Type Questionnaire Item
Analysis*. <https://CRAN.R-project.org/package=Scale>.

Gould-Williams, Julian. 2004. “The Effects of ‘High Commitment’ Hrm
Practices on Employee Attitude: The Views of Public Sector Workers.”
*Public Administration* 82 (1): 63–81.
<https://doi.org/10.1111/j.0033-3298.2004.00383.x>.

Goulet, Laurel R., and Margaret L Frank. 2002. “Organizational
Commitment Across Three Sectors: Public, Non-Profit, and for-Profit.”
*Public Personnel Management* 31 (2): 201–11.

Grimmelikhuijsen, Stephan, Sebastian Jilke, Asmus Leth Olsen, and Lars
Tummers. 2017. “Behavioral Public Administration: Combining Insights
from Public Administration and Psychology.” *Public Administration
Review* 77 (1): 45–56.

Grimmelikhuijsen, Stephan, and Eva Knies. 2017. “Validating a Scale for
Citizen Trust in Government Organizations.” *International Review of
Administrative Sciences* 83 (3): 583–601.
<https://doi.org/10.1177/0020852315585950>.

Halachmi, Arie, and Marc Holzer. 2010. “Citizen Participation and
Performance Measurement: Operationalizing Democracy Through Better
Accountability.” *Public Administration Quarterly* 34 (3): 378–99.

Henn, Matt, Mark Weinstein, and Sarah Forrest. 2005. “Uninterested
Youth? Young People’s Attitudes Towards Party Politics in Britain.”
*Political Studies* 53 (3): 1467–9248.
<https://doi.org/10.1111/j.1467-9248.2005.00544.x>.

Inthorn, Sanna, and John Street. 2011. “Simon Cowell for Prime
Minister’? Young Citizens’ Attitudes Towards Celebrity Politics.”
*Media, Culture & Society* 33 (3): 479–89.
[https://doi.org/10.1177/0163443711398765](https://doi.org/10.1177/0163443711398765 ).

Irvin, Renée A., and John Stansbury. 2004. “Citizen Participation in
Decision Making: Is It Worth the Effort?” *Public Administration Review*
64 (1): 55–65.

James, Oliver. 2011. “Managing Citizens’ Expectations of Public Service
Performance: Evidence from Observation and Experimentation in Local
Government.” *Public Administration* 89 (4): 1419–35.

James, Oliver, Sebastian R. Jilke, and Gregg G. Van Ryzin. 2017.
“Behavioural and Experimental Public Administration: Emerging
Contributions and New Directions.” *Public Administration* 95 (4):
865–73. <https://doi.org/10.1111/padm.12363>.

Jilke, Sebastian. 2017. “Citizen Satisfaction Under Changing Political
Leadership: The Role of Partisan Motivated Reasoning.” *Governance*, –.
<https://doi.org/10.1111/gove.12317>.

Kim, Sangmook, Wouter Vandenabeele, Bradley E. Wright, Lotte Bøgh
Andersen, Francesco Paolo Cerase, Robert K. Christensen, Céline
Desmarais, et al. 2013. “Investigating the Structure and Meaning of
Public Service Motivation Across Populations: Developing an
International Instrument and Addressing Issues of Measurement
Invariance.” *Journal of Public Administration Research and Theory* 23
(1): 79–102. <https://doi.org/10.1093/jopart/mus027>.

Kolsaker, Ailsa, and Liz Lee‐Kelley. 2008. “Citizens’ Attitudes Towards
E‐government and E‐governance: A Uk Study.” *International Journal of
Public Sector Management* 21 (7): 723–38.
<https://doi.org/10.1108/09513550810904532>.

Lee, Geon, and Do Lim Choi. 2016. “Does Public Service Motivation
Influence the College Students’ Intention to Work in the Public Sector?
Evidence from Korea.” *Review of Public Personnel Administration* 36
(2): 145–63. <https://doi.org/10.1177/0734371X13511974>.

Marsh, Herbert W., Kit-Tai Hau, and Zhonghlin Wen. 2004. “In Search of
Golden Rules: Comment on Hypothesis-Testing Approaches to Setting Cutoff
Values for Fit Indexes and Dangers in Overgeneralizing Hu and Bentler’s
(1999) Findings.” *Structural Equation Modeling* 11 (2): 320–41.

Marvel, John D. 2016. “Unconscious Bias in Citizens’ Evaluations of
Public Sector Performance.” *Journal of Public Administration Research
and Theory* 26 (1): 143–58.

McDougle, Lindsey. 2014. “Understanding Public Awareness of Nonprofit
Organizations: Exploring the Awareness–Confidence Relationship.”
*International Journal of Nonprofit and Voluntary Sector Marketing* 19
(3): 187–99.

Morgeson, Forrest V. III. 2013. “Expectations, Disconfirmation, and
Citizen Satisfaction with the Us Federal Government: Testing and
Expanding the Model.” *Journal of Public Administration Research and
Theory* 23 (2): 289–305.

Nielsen, Hans Jorgen. 1981. “Size and Evaluation of Government: Danish
Attitudes Towards Politics at Multiple Levels of Government.” *European
Journal of Political Research* 9 (1): 47–60.
<https://doi.org/10.1111/j.1475-6765.1981.tb00588.x>.

Norman, Geoff. 2010. “Likert Scales, Levels of Measurement and the
‘Laws’ of Statistics.” *Advances in Health Sciences Education* 15 (5):
625–32.

Olsen, Asmus Leth. 2015. “Citizen (Dis) Satisfaction: An Experimental
Equivalence Framing Study.” *Public Administration Review* 75 (3):
469–78.

Pandey, Sanjay K., David H. Coursey, and Donald P. Moynihan. 2007.
“Organizational Effectiveness and Bureaucratic Red Tape: A Multimethod
Study.” *Public Performance & Management Review* 30 (3): 398–425.
<https://doi.org/10.2753/PMR1530-9576300305>.

Perry, James L., and Lois Recascino Wise. 1990. “The Motivational Bases
of Public Service.” *Public Administration Review* 50 (3): 367–73.

R Core Team. 2017. *R: A Language and Environment for Statistical
Computing*. Vienna, Austria: R Foundation for Statistical Computing.
<https://www.R-project.org/>.

Revelle, William. 2017. *Psych: Procedures for Psychological,
Psychometric, and Personality Research*. Evanston, Illinois:
Northwestern University. <https://CRAN.R-project.org/package=psych>.

Roberts, Nancy. 2004. “Public Deliberation in an Age of Direct Citizen
Participation.” *American Review of Public Administration* 34: 315–52.

Rosseel, Yves. 2012. “lavaan: An R Package for Structural Equation
Modeling.” *Journal of Statistical Software* 48 (2): 1–36.
<http://www.jstatsoft.org/v48/i02/>.

Ryzin, Gregg G. Van. 2004. “The Measurement of Overall Citizen
Satisfaction.” *Public Performance & Management Review* 27 (3): 9–28.
<https://doi.org/10.2307/3381143>.

Scherpenzeel, Annett C., and Willem E. Saris. 1997. “The Validity and
Reliability of Survey Questions: A Meta-Analysis of Mtmm Studies.”
*Sociological Methods & Research* 25 (3): 341–83.

Strahan, Robert, and Kathleen Carrese Gerbasi. 1972. “Short, Homogeneous
Versions of the Marlow-Crowne Social Desirability Scale.” *Journal of
Clinical Psychology* 28 (2): 191–93.
[https://doi.org/10.1002/1097-4679(197204)28:2&lt;191::AID-JCLP2270280220&gt;3.0.CO;2-G](https://doi.org/10.1002/1097-4679(197204)28:2<191::AID-JCLP2270280220>3.0.CO;2-G).

Thurstone, Louis Leon. 1928. “Attitudes Can Be Measured.” *American
Journal of Sociology* 33 (4): 529–54.

Vandenabeele, Wouter. 2007. “Toward a Public Administration Theory of
Public Service Motivation: An Institutional Approach.” *Public
Management Review* 9 (4): 545–56.

Vandenabeele, Wouter, and Julia Penning de Vries. 2013. “Validating a
Global Measure of Public Service Motivation: Assessing Measurement
Invariance.” Aarhus, Demark: Public Management Research Conference;
Public Management Research Conference.

Van de Walle, Steven. 2004. “Context-Specific Images of the Archetypical
Bureaucrat: Persistence and Diffusion of the Bureaucracy Stereotype.”
*Public Voices* 7 (1): 3–12.

———. 2008. “Perceptions of Corruption as Distrust? Cause and Effect in
Attitudes Towards Government.” In *Ethics and Integrity and the Politics
of Governance*, edited by L. Huberts, C. Jurkiewicz, and J. Maesschalck,
215–36. Cheltenham: Edward Elgar. <https://ssrn.com/abstract=1307673>.

Van de Walle, Steven, and Gregg G. Van Ryzin. 2011. “The Order of
Questions in a Survey on Citizen Satisfaction with Public Services:
Lessons from a Split‐ballot Experiment.” *Public Administration* 89 (4):
1436–50.

Van Ryzin, Gregg G., Douglas Muzzio, Stephen Immerwahr, Lisa Gulick, and
Eve Martinez. 2004. “Drivers and Consequences of Citizen Satisfaction:
An Application of the American Customer Satisfaction Index Model to New
York City.” *Public Administration Review* 64 (3): 331–41.

Vigoda, Eran. 2000. “Organizational Politics, Job Attitudes, and Work
Outcomes: Exploration and Implications for the Public Sector.” *Journal
of Vocational Behavior* 57 (3): 326–47.
<https://doi.org/10.1006/jvbe.1999.1742>.

Wei, Taiyun, and Viliam Simko. 2017. *R Package "Corrplot":
Visualization of a Correlation Matrix*.
<https://github.com/taiyun/corrplot>.

Weißmüller, Kristina. 2016. “The Grass Is Greener on the Other Side:
Experimental Evidence on the Asymmetric Nature of the Anti-Public Sector
Bias and the Heuristic Formation of Public Opinion.” Poznan, Poland:
IPSA 24th World Congress of Political Sciences; IPSA 24th World Congress
of Political Sciences.

Whitaker, Gordon P. 1980. “Coproduction: Citizen Participation in
Service Delivery.” *Public Administration Review* 40 (3): 240–46.

Willems, Jurgen. 2014. “Antecedents or Effects of Being a Manager in the
Nonprofit, Public or Private Sector.” *Nonprofit Management &
Leadership* 25 (2): 183–89.

———. 2020a. “Public Servant Stereotypes: It Is Not (at) All About Being
Lazy, Greedy, and Corrupt.” *Public Administration* n/a (n/a).
<https://doi.org/10.1111/padm.12686>.

———. 2020b. “Cognitive word associations for "politician" in US,” June.
<https://doi.org/10.6084/m9.figshare.12505430.v1>.

———. 2020c. “Cognitive word associations for "public servant" in US,”
June. <https://doi.org/10.6084/m9.figshare.12505415.v2>.

———. 2020d. “Correlation plot - for attitudes towards the public sector,
public servants, and politicians; and Public service motivation, Trust
in government, Political orientation, Social desirability, etc,” June.
<https://doi.org/10.6084/m9.figshare.12571232.v1>.

Wright, Bradley E., Shahidul Hassan, and Robert K. Christensen. 2017.
“Job Choice and Performance: Revisiting Core Assumptions About Public
Service Motivation.” *International Public Management Journal* 20 (1):
108–31. <https://doi.org/10.1080/10967494.2015.1088493>.

Yang, Kaifeng, and Kathe Callahan. 2007. “Citizen Involvement Efforts
and Bureaucratic Responsiveness.” *Public Administration Review* 67 (2):
249–64.
